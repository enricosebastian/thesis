(new-model-maker) enricosebastian@enricosebastian-MS-7A66:~/Desktop/thesis/tflite/prototype/main-05-new-model-maker-version$ /home/enricosebastian/miniconda3/envs/new-model-maker/bin/python /home/enricosebastian/Desktop/thesis/tflite/prototype/main-05-new-model-maker-version/model-maker.py
/home/enricosebastian/miniconda3/envs/new-model-maker/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.8.4 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2023-03-31 03:07:19.055560: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.071285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.071533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.072095: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-31 03:07:19.072705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.072985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.073168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.485174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.485504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.485697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 03:07:19.485846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4863 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1
Epoch 1/25
2023-03-31 03:07:46.764841: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100
2023-03-31 03:07:47.064714: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-03-31 03:07:47.065449: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-03-31 03:07:47.065479: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version
2023-03-31 03:07:47.066207: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-03-31 03:07:47.066281: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
32/32 [==============================] - 33s 356ms/step - det_loss: 1.6448 - cls_loss: 1.1377 - box_loss: 0.0101 - reg_l2_loss: 0.0633 - loss: 1.7081 - learning_rate: 0.0090 - gradient_norm: 1.3545 - val_det_loss: 1.4776 - val_cls_loss: 1.0890 - val_box_loss: 0.0078 - val_reg_l2_loss: 0.0633 - val_loss: 1.5409
Epoch 2/25
32/32 [==============================] - 9s 281ms/step - det_loss: 1.2360 - cls_loss: 0.9516 - box_loss: 0.0057 - reg_l2_loss: 0.0634 - loss: 1.2994 - learning_rate: 0.0099 - gradient_norm: 1.7169 - val_det_loss: 0.9435 - val_cls_loss: 0.7244 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0634 - val_loss: 1.0069
Epoch 3/25
32/32 [==============================] - 9s 280ms/step - det_loss: 0.7530 - cls_loss: 0.6259 - box_loss: 0.0025 - reg_l2_loss: 0.0634 - loss: 0.8164 - learning_rate: 0.0097 - gradient_norm: 1.6408 - val_det_loss: 1.1216 - val_cls_loss: 0.6467 - val_box_loss: 0.0095 - val_reg_l2_loss: 0.0634 - val_loss: 1.1850
Epoch 4/25
32/32 [==============================] - 9s 279ms/step - det_loss: 0.5588 - cls_loss: 0.4935 - box_loss: 0.0013 - reg_l2_loss: 0.0634 - loss: 0.6222 - learning_rate: 0.0095 - gradient_norm: 1.6412 - val_det_loss: 1.1270 - val_cls_loss: 0.6674 - val_box_loss: 0.0092 - val_reg_l2_loss: 0.0634 - val_loss: 1.1904
Epoch 5/25
32/32 [==============================] - 14s 442ms/step - det_loss: 0.4752 - cls_loss: 0.4338 - box_loss: 8.2669e-04 - reg_l2_loss: 0.0634 - loss: 0.5386 - learning_rate: 0.0092 - gradient_norm: 1.6610 - val_det_loss: 0.7792 - val_cls_loss: 0.5214 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0635 - val_loss: 0.8427
Epoch 6/25
32/32 [==============================] - 9s 273ms/step - det_loss: 0.4166 - cls_loss: 0.3843 - box_loss: 6.4680e-04 - reg_l2_loss: 0.0635 - loss: 0.4801 - learning_rate: 0.0088 - gradient_norm: 1.6059 - val_det_loss: 0.4907 - val_cls_loss: 0.4228 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0635 - val_loss: 0.5542
Epoch 7/25
32/32 [==============================] - 9s 275ms/step - det_loss: 0.3970 - cls_loss: 0.3626 - box_loss: 6.8794e-04 - reg_l2_loss: 0.0635 - loss: 0.4605 - learning_rate: 0.0083 - gradient_norm: 1.7344 - val_det_loss: 0.8913 - val_cls_loss: 0.5224 - val_box_loss: 0.0074 - val_reg_l2_loss: 0.0635 - val_loss: 0.9548
Epoch 8/25
32/32 [==============================] - 9s 287ms/step - det_loss: 0.3558 - cls_loss: 0.3308 - box_loss: 5.0113e-04 - reg_l2_loss: 0.0635 - loss: 0.4193 - learning_rate: 0.0078 - gradient_norm: 1.6973 - val_det_loss: 0.9120 - val_cls_loss: 0.5178 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0635 - val_loss: 0.9755
Epoch 9/25
32/32 [==============================] - 9s 283ms/step - det_loss: 0.3294 - cls_loss: 0.3065 - box_loss: 4.5751e-04 - reg_l2_loss: 0.0635 - loss: 0.3929 - learning_rate: 0.0072 - gradient_norm: 1.7226 - val_det_loss: 1.0679 - val_cls_loss: 0.5932 - val_box_loss: 0.0095 - val_reg_l2_loss: 0.0635 - val_loss: 1.1314
Epoch 10/25
32/32 [==============================] - 10s 327ms/step - det_loss: 0.3209 - cls_loss: 0.3017 - box_loss: 3.8510e-04 - reg_l2_loss: 0.0635 - loss: 0.3844 - learning_rate: 0.0066 - gradient_norm: 1.7211 - val_det_loss: 1.0398 - val_cls_loss: 0.5913 - val_box_loss: 0.0090 - val_reg_l2_loss: 0.0635 - val_loss: 1.1033
Epoch 11/25
32/32 [==============================] - 9s 272ms/step - det_loss: 0.2905 - cls_loss: 0.2764 - box_loss: 2.8117e-04 - reg_l2_loss: 0.0635 - loss: 0.3540 - learning_rate: 0.0060 - gradient_norm: 1.4367 - val_det_loss: 1.1840 - val_cls_loss: 0.6962 - val_box_loss: 0.0098 - val_reg_l2_loss: 0.0635 - val_loss: 1.2475
Epoch 12/25
32/32 [==============================] - 9s 291ms/step - det_loss: 0.2861 - cls_loss: 0.2731 - box_loss: 2.5908e-04 - reg_l2_loss: 0.0635 - loss: 0.3496 - learning_rate: 0.0053 - gradient_norm: 1.5366 - val_det_loss: 0.5703 - val_cls_loss: 0.4614 - val_box_loss: 0.0022 - val_reg_l2_loss: 0.0635 - val_loss: 0.6338
Epoch 13/25
32/32 [==============================] - 9s 273ms/step - det_loss: 0.2684 - cls_loss: 0.2551 - box_loss: 2.6569e-04 - reg_l2_loss: 0.0635 - loss: 0.3320 - learning_rate: 0.0047 - gradient_norm: 1.5780 - val_det_loss: 0.4253 - val_cls_loss: 0.3013 - val_box_loss: 0.0025 - val_reg_l2_loss: 0.0635 - val_loss: 0.4889
Epoch 14/25
32/32 [==============================] - 9s 274ms/step - det_loss: 0.2522 - cls_loss: 0.2405 - box_loss: 2.3234e-04 - reg_l2_loss: 0.0635 - loss: 0.3157 - learning_rate: 0.0040 - gradient_norm: 1.4099 - val_det_loss: 0.4128 - val_cls_loss: 0.2877 - val_box_loss: 0.0025 - val_reg_l2_loss: 0.0635 - val_loss: 0.4763
Epoch 15/25
32/32 [==============================] - 10s 319ms/step - det_loss: 0.2517 - cls_loss: 0.2401 - box_loss: 2.3079e-04 - reg_l2_loss: 0.0635 - loss: 0.3152 - learning_rate: 0.0034 - gradient_norm: 1.5208 - val_det_loss: 0.5612 - val_cls_loss: 0.3418 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0635 - val_loss: 0.6248
Epoch 16/25
32/32 [==============================] - 9s 280ms/step - det_loss: 0.2436 - cls_loss: 0.2325 - box_loss: 2.2286e-04 - reg_l2_loss: 0.0635 - loss: 0.3071 - learning_rate: 0.0028 - gradient_norm: 1.3550 - val_det_loss: 0.2889 - val_cls_loss: 0.2488 - val_box_loss: 8.0165e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3524
Epoch 17/25
32/32 [==============================] - 9s 281ms/step - det_loss: 0.2353 - cls_loss: 0.2237 - box_loss: 2.3228e-04 - reg_l2_loss: 0.0635 - loss: 0.2989 - learning_rate: 0.0022 - gradient_norm: 1.6102 - val_det_loss: 0.2973 - val_cls_loss: 0.2515 - val_box_loss: 9.1689e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3609
Epoch 18/25
32/32 [==============================] - 9s 282ms/step - det_loss: 0.2266 - cls_loss: 0.2161 - box_loss: 2.0916e-04 - reg_l2_loss: 0.0635 - loss: 0.2901 - learning_rate: 0.0017 - gradient_norm: 1.6308 - val_det_loss: 0.4937 - val_cls_loss: 0.3073 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0635 - val_loss: 0.5572
Epoch 19/25
32/32 [==============================] - 9s 282ms/step - det_loss: 0.2375 - cls_loss: 0.2257 - box_loss: 2.3619e-04 - reg_l2_loss: 0.0635 - loss: 0.3010 - learning_rate: 0.0012 - gradient_norm: 1.6190 - val_det_loss: 0.2651 - val_cls_loss: 0.2350 - val_box_loss: 6.0273e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3286
Epoch 20/25
 7/32 [=====>........................] - ETA: 5s - det_loss: 0.1870 - cls_loss: 0.1756 - box_loss: 2.2891e-04 - reg_l2_loss: 0.0635 - loss: 0.2506 - learning_rate: 9.9631e-04 - gradient_norm: 1.4 8/32 [======>.......................] - ETA: 5s - det_loss: 0.2009 - cls_loss: 0.1899 - box_loss: 2.1954e-04 - reg_l2_loss: 0.0635 - loss: 0.2644 - learning_rate: 9.9024e-04 - gradient_norm: 1.4 9/32 [=======>......................] - ETA: 5s - det_loss: 0.2047 - cls_loss: 0.1928 - box_loss: 2.3766e-04 - reg_l2_loss: 0.0635 - loss: 0.2682 - learning_rate: 9.8419e-04 - gradient_norm: 1.310/32 [========>.....................] - ETA: 4s - det_loss: 0.2101 - cls_loss: 0.1982 - box_loss: 2.3816e-04 - reg_l2_loss: 0.0635 - loss: 0.2737 - learning_rate: 9.7816e-04 - gradient_norm: 1.311/32 [=========>....................] - ETA: 4s - det_loss: 0.2219 - cls_loss: 0.2082 - box_loss: 2.7330e-04 - reg_l2_loss: 0.0635 - loss: 0.2854 - learning_rate: 9.7215e-04 - gradient_norm: 1.512/32 [==========>...................] - ETA: 4s - det_loss: 0.2189 - cls_loss: 0.2057 - box_loss: 2.6533e-04 - reg_l2_loss: 0.0635 - loss: 0.2825 - learning_rate: 9.6616e-04 - gradient_norm: 1.613/32 [===========>..................] - ETA: 4s - det_loss: 0.2237 - cls_loss: 0.2092 - box_loss: 2.8896e-04 - reg_l2_loss: 0.0635 - loss: 0.2872 - learning_rate: 9.6020e-04 - gradient_norm: 1.614/32 [============>.................] - ETA: 3s - det_loss: 0.2285 - cls_loss: 0.2138 - box_loss: 2.9470e-04 - reg_l2_loss: 0.0635 - loss: 0.2921 - learning_rate: 9.5426e-04 - gradient_norm: 1.615/32 [=============>................] - ETA: 3s - det_loss: 0.2300 - cls_loss: 0.2158 - box_loss: 2.8403e-04 - reg_l2_loss: 0.0635 - loss: 0.2935 - learning_rate: 9.4835e-04 - gradient_norm: 1.616/32 [==============>...............] - ETA: 3s - det_loss: 0.2314 - cls_loss: 0.2157 - box_loss: 3.1282e-04 - reg_l2_loss: 0.0635 - loss: 0.2949 - learning_rate: 9.4245e-04 - gradient_norm: 1.617/32 [==============>...............] - ETA: 3s - det_loss: 0.2332 - cls_loss: 0.2176 - box_loss: 3.1098e-04 - reg_l2_loss: 0.0635 - loss: 0.2967 - learning_rate: 9.3658e-04 - gradient_norm: 1.718/32 [===============>..............] - ETA: 3s - det_loss: 0.2371 - cls_loss: 0.2214 - box_loss: 3.1285e-04 - reg_l2_loss: 0.0635 - loss: 0.3006 - learning_rate: 9.3073e-04 - gradient_norm: 1.719/32 [================>.............] - ETA: 2s - det_loss: 0.2349 - cls_loss: 0.2196 - box_loss: 3.0489e-04 - reg_l2_loss: 0.0635 - loss: 0.2984 - learning_rate: 9.2491e-04 - gradient_norm: 1.620/32 [=================>............] - ETA: 2s - det_loss: 0.2321 - cls_loss: 0.2172 - box_loss: 2.9761e-04 - reg_l2_loss: 0.0635 - loss: 0.2957 - learning_rate: 9.1911e-04 - gradient_norm: 1.621/32 [==================>...........] - ETA: 2s - det_loss: 0.2297 - cls_loss: 0.2150 - box_loss: 2.9358e-04 - reg_l2_loss: 0.0635 - loss: 0.2932 - learning_rate: 9.1333e-04 - gradient_norm: 1.522/32 [===================>..........] - ETA: 2s - det_loss: 0.2305 - cls_loss: 0.2158 - box_loss: 2.9381e-04 - reg_l2_loss: 0.0635 - loss: 0.2941 - learning_rate: 9.0757e-04 - gradient_norm: 1.523/32 [====================>.........] - ETA: 2s - det_loss: 0.2299 - cls_loss: 0.2154 - box_loss: 2.8970e-04 - reg_l2_loss: 0.0635 - loss: 0.2935 - learning_rate: 9.0184e-04 - gradient_norm: 1.524/32 [=====================>........] - ETA: 1s - det_loss: 0.2256 - cls_loss: 0.2114 - box_loss: 2.8319e-04 - reg_l2_loss: 0.0635 - loss: 0.2891 - learning_rate: 8.9613e-04 - gradient_norm: 1.525/32 [======================>.......] - ETA: 1s - det_loss: 0.2251 - cls_loss: 0.2109 - box_loss: 2.8298e-04 - reg_l2_loss: 0.0635 - loss: 0.2886 - learning_rate: 8.9045e-04 - gradient_norm: 1.526/32 [=======================>......] - ETA: 1s - det_loss: 0.2220 - cls_loss: 0.2080 - box_loss: 2.7906e-04 - reg_l2_loss: 0.0635 - loss: 0.2855 - learning_rate: 8.8478e-04 - gradient_norm: 1.427/32 [========================>.....] - ETA: 1s - det_loss: 0.2229 - cls_loss: 0.2091 - box_loss: 2.7747e-04 - reg_l2_loss: 0.0635 - loss: 0.2865 - learning_rate: 8.7915e-04 - gradient_norm: 1.528/32 [=========================>....] - ETA: 0s - det_loss: 0.2214 - cls_loss: 0.2074 - box_loss: 2.7995e-04 - reg_l2_loss: 0.0635 - loss: 0.2849 - learning_rate: 8.7353e-04 - gradient_norm: 1.429/32 [==========================>...] - ETA: 0s - det_loss: 0.2218 - cls_loss: 0.2081 - box_loss: 2.7401e-04 - reg_l2_loss: 0.0635 - loss: 0.2854 - learning_rate: 8.6794e-04 - gradient_norm: 1.430/32 [===========================>..] - ETA: 0s - det_loss: 0.2211 - cls_loss: 0.2076 - box_loss: 2.6987e-04 - reg_l2_loss: 0.0635 - loss: 0.2847 - learning_rate: 8.6237e-04 - gradient_norm: 1.531/32 [============================>.] - ETA: 0s - det_loss: 0.2226 - cls_loss: 0.2092 - box_loss: 2.6736e-04 - reg_l2_loss: 0.0635 - loss: 0.2861 - learning_rate: 8.5682e-04 - gradient_norm: 1.432/32 [==============================] - ETA: 0s - det_loss: 0.2227 - cls_loss: 0.2094 - box_loss: 2.6567e-04 - reg_l2_loss: 0.0635 - loss: 0.2863 - learning_rate: 8.5130e-04 - gradient_norm: 1.432/32 [==============================] - 11s 336ms/step - det_loss: 0.2228 - cls_loss: 0.2096 - box_loss: 2.6408e-04 - reg_l2_loss: 0.0635 - loss: 0.2864 - learning_rate: 8.4612e-04 - gradient_norm: 1.4684 - val_det_loss: 0.2753 - val_cls_loss: 0.2352 - val_box_loss: 8.0142e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3389
Epoch 21/25
 1/32 [..............................] - ETA: 6s - det_loss: 0.2236 - cls_loss: 0.2153 - box_loss: 1.6516e-04 - reg_l2_loss: 0.0635 - loss: 0.2871 - learning_rate: 6.6987e-04 - gradient_norm: 1.4 2/32 [>.............................] - ETA: 6s - det_loss: 0.2175 - cls_loss: 0.2084 - box_loss: 1.8088e-04 - reg_l2_loss: 0.0635 - loss: 0.2810 - learning_rate: 6.6478e-04 - gradient_norm: 1.2 3/32 [=>............................] - ETA: 6s - det_loss: 0.2091 - cls_loss: 0.2000 - box_loss: 1.8310e-04 - reg_l2_loss: 0.0635 - loss: 0.2727 - learning_rate: 6.5971e-04 - gradient_norm: 1.2 4/32 [==>...........................] - ETA: 6s - det_loss: 0.2144 - cls_loss: 0.2041 - box_loss: 2.0695e-04 - reg_l2_loss: 0.0635 - loss: 0.2780 - learning_rate: 6.5466e-04 - gradient_norm: 1.5 5/32 [===>..........................] - ETA: 5s - det_loss: 0.2186 - cls_loss: 0.2091 - box_loss: 1.8966e-04 - reg_l2_loss: 0.0635 - loss: 0.2821 - learning_rate: 6.4964e-04 - gradient_norm: 1.7 6/32 [====>.........................] - ETA: 5s - det_loss: 0.2221 - cls_loss: 0.2132 - box_loss: 1.7766e-04 - reg_l2_loss: 0.0635 - loss: 0.2856 - learning_rate: 6.4464e-04 - gradient_norm: 1.8 7/32 [=====>........................] - ETA: 5s - det_loss: 0.2244 - cls_loss: 0.2149 - box_loss: 1.9070e-04 - reg_l2_loss: 0.0635 - loss: 0.2880 - learning_rate: 6.3967e-04 - gradient_norm: 1.8 8/32 [======>.......................] - ETA: 5s - det_loss: 0.2295 - cls_loss: 0.2191 - box_loss: 2.0795e-04 - reg_l2_loss: 0.0635 - loss: 0.2931 - learning_rate: 6.3472e-04 - gradient_norm: 1.9 9/32 [=======>......................] - ETA: 5s - det_loss: 0.2496 - cls_loss: 0.2370 - box_loss: 2.5136e-04 - reg_l2_loss: 0.0635 - loss: 0.3132 - learning_rate: 6.2979e-04 - gradient_norm: 2.110/32 [========>.....................] - ETA: 4s - det_loss: 0.2418 - cls_loss: 0.2291 - box_loss: 2.5333e-04 - reg_l2_loss: 0.0635 - loss: 0.3053 - learning_rate: 6.2489e-04 - gradient_norm: 2.011/32 [=========>....................] - ETA: 4s - det_loss: 0.2363 - cls_loss: 0.2239 - box_loss: 2.4836e-04 - reg_l2_loss: 0.0635 - loss: 0.2999 - learning_rate: 6.2002e-04 - gradient_norm: 1.812/32 [==========>...................] - ETA: 4s - det_loss: 0.2383 - cls_loss: 0.2263 - box_loss: 2.3973e-04 - reg_l2_loss: 0.0635 - loss: 0.3018 - learning_rate: 6.1516e-04 - gradient_norm: 1.813/32 [===========>..................] - ETA: 4s - det_loss: 0.2353 - cls_loss: 0.2236 - box_loss: 2.3313e-04 - reg_l2_loss: 0.0635 - loss: 0.2988 - learning_rate: 6.1034e-04 - gradient_norm: 1.814/32 [============>.................] - ETA: 3s - det_loss: 0.2375 - cls_loss: 0.2258 - box_loss: 2.3504e-04 - reg_l2_loss: 0.0635 - loss: 0.3011 - learning_rate: 6.0554e-04 - gradient_norm: 1.915/32 [=============>................] - ETA: 3s - det_loss: 0.2358 - cls_loss: 0.2243 - box_loss: 2.2951e-04 - reg_l2_loss: 0.0635 - loss: 0.2993 - learning_rate: 6.0076e-04 - gradient_norm: 1.916/32 [==============>...............] - ETA: 3s - det_loss: 0.2345 - cls_loss: 0.2232 - box_loss: 2.2615e-04 - reg_l2_loss: 0.0635 - loss: 0.2980 - learning_rate: 5.9601e-04 - gradient_norm: 1.917/32 [==============>...............] - ETA: 3s - det_loss: 0.2294 - cls_loss: 0.2183 - box_loss: 2.2034e-04 - reg_l2_loss: 0.0635 - loss: 0.2929 - learning_rate: 5.9128e-04 - gradient_norm: 1.918/32 [===============>..............] - ETA: 3s - det_loss: 0.2381 - cls_loss: 0.2271 - box_loss: 2.2066e-04 - reg_l2_loss: 0.0635 - loss: 0.3017 - learning_rate: 5.8658e-04 - gradient_norm: 1.919/32 [================>.............] - ETA: 2s - det_loss: 0.2358 - cls_loss: 0.2250 - box_loss: 2.1696e-04 - reg_l2_loss: 0.0635 - loss: 0.2994 - learning_rate: 5.8190e-04 - gradient_norm: 1.820/32 [=================>............] - ETA: 2s - det_loss: 0.2366 - cls_loss: 0.2256 - box_loss: 2.1959e-04 - reg_l2_loss: 0.0635 - loss: 0.3001 - learning_rate: 5.7724e-04 - gradient_norm: 1.821/32 [==================>...........] - ETA: 2s - det_loss: 0.2344 - cls_loss: 0.2236 - box_loss: 2.1735e-04 - reg_l2_loss: 0.0635 - loss: 0.2980 - learning_rate: 5.7262e-04 - gradient_norm: 1.822/32 [===================>..........] - ETA: 2s - det_loss: 0.2323 - cls_loss: 0.2213 - box_loss: 2.1880e-04 - reg_l2_loss: 0.0635 - loss: 0.2958 - learning_rate: 5.6801e-04 - gradient_norm: 1.723/32 [====================>.........] - ETA: 1s - det_loss: 0.2315 - cls_loss: 0.2207 - box_loss: 2.1659e-04 - reg_l2_loss: 0.0635 - loss: 0.2951 - learning_rate: 5.6344e-04 - gradient_norm: 1.724/32 [=====================>........] - ETA: 1s - det_loss: 0.2301 - cls_loss: 0.2192 - box_loss: 2.1863e-04 - reg_l2_loss: 0.0635 - loss: 0.2936 - learning_rate: 5.5888e-04 - gradient_norm: 1.725/32 [======================>.......] - ETA: 1s - det_loss: 0.2269 - cls_loss: 0.2161 - box_loss: 2.1754e-04 - reg_l2_loss: 0.0635 - loss: 0.2905 - learning_rate: 5.5435e-04 - gradient_norm: 1.726/32 [=======================>......] - ETA: 1s - det_loss: 0.2253 - cls_loss: 0.2146 - box_loss: 2.1365e-04 - reg_l2_loss: 0.0635 - loss: 0.2889 - learning_rate: 5.4985e-04 - gradient_norm: 1.727/32 [========================>.....] - ETA: 1s - det_loss: 0.2240 - cls_loss: 0.2133 - box_loss: 2.1448e-04 - reg_l2_loss: 0.0635 - loss: 0.2876 - learning_rate: 5.4537e-04 - gradient_norm: 1.728/32 [=========================>....] - ETA: 0s - det_loss: 0.2214 - cls_loss: 0.2107 - box_loss: 2.1224e-04 - reg_l2_loss: 0.0635 - loss: 0.2849 - learning_rate: 5.4092e-04 - gradient_norm: 1.729/32 [==========================>...] - ETA: 0s - det_loss: 0.2200 - cls_loss: 0.2093 - box_loss: 2.1215e-04 - reg_l2_loss: 0.0635 - loss: 0.2835 - learning_rate: 5.3649e-04 - gradient_norm: 1.630/32 [===========================>..] - ETA: 0s - det_loss: 0.2183 - cls_loss: 0.2078 - box_loss: 2.1102e-04 - reg_l2_loss: 0.0635 - loss: 0.2819 - learning_rate: 5.3209e-04 - gradient_norm: 1.631/32 [============================>.] - ETA: 0s - det_loss: 0.2180 - cls_loss: 0.2071 - box_loss: 2.1936e-04 - reg_l2_loss: 0.0635 - loss: 0.2816 - learning_rate: 5.2771e-04 - gradient_norm: 1.632/32 [==============================] - ETA: 0s - det_loss: 0.2173 - cls_loss: 0.2062 - box_loss: 2.2147e-04 - reg_l2_loss: 0.0635 - loss: 0.2809 - learning_rate: 5.2336e-04 - gradient_norm: 1.632/32 [==============================] - 9s 279ms/step - det_loss: 0.2167 - cls_loss: 0.2055 - box_loss: 2.2346e-04 - reg_l2_loss: 0.0635 - loss: 0.2802 - learning_rate: 5.1928e-04 - gradient_norm: 1.5855 - val_det_loss: 0.2528 - val_cls_loss: 0.2406 - val_box_loss: 2.4321e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3164
Epoch 22/25
 1/32 [..............................] - ETA: 7s - det_loss: 0.2090 - cls_loss: 0.1921 - box_loss: 3.3829e-04 - reg_l2_loss: 0.0635 - loss: 0.2726 - learning_rate: 3.8060e-04 - gradient_norm: 1.6 2/32 [>.............................] - ETA: 6s - det_loss: 0.2042 - cls_loss: 0.1908 - box_loss: 2.6798e-04 - reg_l2_loss: 0.0635 - loss: 0.2677 - learning_rate: 3.7671e-04 - gradient_norm: 1.7 3/32 [=>............................] - ETA: 6s - det_loss: 0.2170 - cls_loss: 0.2039 - box_loss: 2.6214e-04 - reg_l2_loss: 0.0635 - loss: 0.2806 - learning_rate: 3.7284e-04 - gradient_norm: 1.9 4/32 [==>...........................] - ETA: 6s - det_loss: 0.2204 - cls_loss: 0.2077 - box_loss: 2.5341e-04 - reg_l2_loss: 0.0635 - loss: 0.2839 - learning_rate: 3.6900e-04 - gradient_norm: 1.7 5/32 [===>..........................] - ETA: 6s - det_loss: 0.2168 - cls_loss: 0.2056 - box_loss: 2.2413e-04 - reg_l2_loss: 0.0635 - loss: 0.2804 - learning_rate: 3.6518e-04 - gradient_norm: 1.5 6/32 [====>.........................] - ETA: 6s - det_loss: 0.2185 - cls_loss: 0.2076 - box_loss: 2.1919e-04 - reg_l2_loss: 0.0635 - loss: 0.2821 - learning_rate: 3.6139e-04 - gradient_norm: 1.7 7/32 [=====>........................] - ETA: 5s - det_loss: 0.2210 - cls_loss: 0.2104 - box_loss: 2.1132e-04 - reg_l2_loss: 0.0635 - loss: 0.2845 - learning_rate: 3.5762e-04 - gradient_norm: 1.6 8/32 [======>.......................] - ETA: 5s - det_loss: 0.2196 - cls_loss: 0.2084 - box_loss: 2.2350e-04 - reg_l2_loss: 0.0635 - loss: 0.2831 - learning_rate: 3.5389e-04 - gradient_norm: 1.6 9/32 [=======>......................] - ETA: 5s - det_loss: 0.2236 - cls_loss: 0.2129 - box_loss: 2.1509e-04 - reg_l2_loss: 0.0635 - loss: 0.2872 - learning_rate: 3.5017e-04 - gradient_norm: 1.610/32 [========>.....................] - ETA: 5s - det_loss: 0.2200 - cls_loss: 0.2096 - box_loss: 2.0701e-04 - reg_l2_loss: 0.0635 - loss: 0.2835 - learning_rate: 3.4649e-04 - gradient_norm: 1.511/32 [=========>....................] - ETA: 4s - det_loss: 0.2264 - cls_loss: 0.2154 - box_loss: 2.2099e-04 - reg_l2_loss: 0.0635 - loss: 0.2900 - learning_rate: 3.4283e-04 - gradient_norm: 1.712/32 [==========>...................] - ETA: 4s - det_loss: 0.2281 - cls_loss: 0.2171 - box_loss: 2.2145e-04 - reg_l2_loss: 0.0635 - loss: 0.2917 - learning_rate: 3.3919e-04 - gradient_norm: 1.613/32 [===========>..................] - ETA: 4s - det_loss: 0.2213 - cls_loss: 0.2102 - box_loss: 2.2141e-04 - reg_l2_loss: 0.0635 - loss: 0.2848 - learning_rate: 3.3558e-04 - gradient_norm: 1.514/32 [============>.................] - ETA: 4s - det_loss: 0.2213 - cls_loss: 0.2105 - box_loss: 2.1588e-04 - reg_l2_loss: 0.0635 - loss: 0.2848 - learning_rate: 3.3200e-04 - gradient_norm: 1.515/32 [=============>................] - ETA: 3s - det_loss: 0.2210 - cls_loss: 0.2105 - box_loss: 2.1043e-04 - reg_l2_loss: 0.0635 - loss: 0.2845 - learning_rate: 3.2844e-04 - gradient_norm: 1.516/32 [==============>...............] - ETA: 3s - det_loss: 0.2190 - cls_loss: 0.2082 - box_loss: 2.1668e-04 - reg_l2_loss: 0.0635 - loss: 0.2826 - learning_rate: 3.2491e-04 - gradient_norm: 1.417/32 [==============>...............] - ETA: 3s - det_loss: 0.2199 - cls_loss: 0.2093 - box_loss: 2.1331e-04 - reg_l2_loss: 0.0635 - loss: 0.2835 - learning_rate: 3.2141e-04 - gradient_norm: 1.418/32 [===============>..............] - ETA: 3s - det_loss: 0.2178 - cls_loss: 0.2070 - box_loss: 2.1609e-04 - reg_l2_loss: 0.0635 - loss: 0.2814 - learning_rate: 3.1793e-04 - gradient_norm: 1.419/32 [================>.............] - ETA: 2s - det_loss: 0.2169 - cls_loss: 0.2061 - box_loss: 2.1584e-04 - reg_l2_loss: 0.0635 - loss: 0.2805 - learning_rate: 3.1448e-04 - gradient_norm: 1.320/32 [=================>............] - ETA: 2s - det_loss: 0.2247 - cls_loss: 0.2138 - box_loss: 2.1785e-04 - reg_l2_loss: 0.0635 - loss: 0.2883 - learning_rate: 3.1106e-04 - gradient_norm: 1.621/32 [==================>...........] - ETA: 2s - det_loss: 0.2281 - cls_loss: 0.2173 - box_loss: 2.1688e-04 - reg_l2_loss: 0.0635 - loss: 0.2917 - learning_rate: 3.0766e-04 - gradient_norm: 1.622/32 [===================>..........] - ETA: 2s - det_loss: 0.2268 - cls_loss: 0.2158 - box_loss: 2.1980e-04 - reg_l2_loss: 0.0635 - loss: 0.2903 - learning_rate: 3.0429e-04 - gradient_norm: 1.623/32 [====================>.........] - ETA: 2s - det_loss: 0.2300 - cls_loss: 0.2191 - box_loss: 2.1839e-04 - reg_l2_loss: 0.0635 - loss: 0.2935 - learning_rate: 3.0094e-04 - gradient_norm: 1.624/32 [=====================>........] - ETA: 1s - det_loss: 0.2292 - cls_loss: 0.2180 - box_loss: 2.2225e-04 - reg_l2_loss: 0.0635 - loss: 0.2927 - learning_rate: 2.9762e-04 - gradient_norm: 1.725/32 [======================>.......] - ETA: 1s - det_loss: 0.2272 - cls_loss: 0.2161 - box_loss: 2.2305e-04 - reg_l2_loss: 0.0635 - loss: 0.2908 - learning_rate: 2.9433e-04 - gradient_norm: 1.726/32 [=======================>......] - ETA: 1s - det_loss: 0.2280 - cls_loss: 0.2168 - box_loss: 2.2454e-04 - reg_l2_loss: 0.0635 - loss: 0.2916 - learning_rate: 2.9106e-04 - gradient_norm: 1.727/32 [========================>.....] - ETA: 1s - det_loss: 0.2283 - cls_loss: 0.2173 - box_loss: 2.2148e-04 - reg_l2_loss: 0.0635 - loss: 0.2919 - learning_rate: 2.8782e-04 - gradient_norm: 1.728/32 [=========================>....] - ETA: 0s - det_loss: 0.2279 - cls_loss: 0.2170 - box_loss: 2.1715e-04 - reg_l2_loss: 0.0635 - loss: 0.2914 - learning_rate: 2.8461e-04 - gradient_norm: 1.729/32 [==========================>...] - ETA: 0s - det_loss: 0.2281 - cls_loss: 0.2173 - box_loss: 2.1492e-04 - reg_l2_loss: 0.0635 - loss: 0.2916 - learning_rate: 2.8142e-04 - gradient_norm: 1.730/32 [===========================>..] - ETA: 0s - det_loss: 0.2253 - cls_loss: 0.2147 - box_loss: 2.1239e-04 - reg_l2_loss: 0.0635 - loss: 0.2888 - learning_rate: 2.7826e-04 - gradient_norm: 1.731/32 [============================>.] - ETA: 0s - det_loss: 0.2255 - cls_loss: 0.2148 - box_loss: 2.1395e-04 - reg_l2_loss: 0.0635 - loss: 0.2890 - learning_rate: 2.7513e-04 - gradient_norm: 1.732/32 [==============================] - ETA: 0s - det_loss: 0.2281 - cls_loss: 0.2173 - box_loss: 2.1688e-04 - reg_l2_loss: 0.0635 - loss: 0.2917 - learning_rate: 2.7202e-04 - gradient_norm: 1.732/32 [==============================] - 9s 273ms/step - det_loss: 0.2307 - cls_loss: 0.2197 - box_loss: 2.1963e-04 - reg_l2_loss: 0.0635 - loss: 0.2942 - learning_rate: 2.6910e-04 - gradient_norm: 1.8178 - val_det_loss: 0.2604 - val_cls_loss: 0.2519 - val_box_loss: 1.7023e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3239
Epoch 23/25
 1/32 [..............................] - ETA: 7s - det_loss: 0.2489 - cls_loss: 0.2357 - box_loss: 2.6319e-04 - reg_l2_loss: 0.0635 - loss: 0.3124 - learning_rate: 1.7037e-04 - gradient_norm: 1.0 2/32 [>.............................] - ETA: 6s - det_loss: 0.2358 - cls_loss: 0.2232 - box_loss: 2.5219e-04 - reg_l2_loss: 0.0635 - loss: 0.2994 - learning_rate: 1.6774e-04 - gradient_norm: 0.9 3/32 [=>............................] - ETA: 6s - det_loss: 0.2283 - cls_loss: 0.2175 - box_loss: 2.1534e-04 - reg_l2_loss: 0.0635 - loss: 0.2919 - learning_rate: 1.6514e-04 - gradient_norm: 1.4 4/32 [==>...........................] - ETA: 6s - det_loss: 0.2179 - cls_loss: 0.2071 - box_loss: 2.1621e-04 - reg_l2_loss: 0.0635 - loss: 0.2815 - learning_rate: 1.6257e-04 - gradient_norm: 1.4 5/32 [===>..........................] - ETA: 5s - det_loss: 0.2150 - cls_loss: 0.2050 - box_loss: 2.0124e-04 - reg_l2_loss: 0.0635 - loss: 0.2786 - learning_rate: 1.6003e-04 - gradient_norm: 1.2 6/32 [====>.........................] - ETA: 5s - det_loss: 0.2230 - cls_loss: 0.2130 - box_loss: 2.0055e-04 - reg_l2_loss: 0.0635 - loss: 0.2865 - learning_rate: 1.5751e-04 - gradient_norm: 1.2 7/32 [=====>........................] - ETA: 5s - det_loss: 0.2198 - cls_loss: 0.2101 - box_loss: 1.9311e-04 - reg_l2_loss: 0.0635 - loss: 0.2833 - learning_rate: 1.5502e-04 - gradient_norm: 1.2 8/32 [======>.......................] - ETA: 5s - det_loss: 0.2119 - cls_loss: 0.2021 - box_loss: 1.9576e-04 - reg_l2_loss: 0.0635 - loss: 0.2754 - learning_rate: 1.5255e-04 - gradient_norm: 1.2 9/32 [=======>......................] - ETA: 4s - det_loss: 0.2139 - cls_loss: 0.2040 - box_loss: 1.9872e-04 - reg_l2_loss: 0.0635 - loss: 0.2775 - learning_rate: 1.5011e-04 - gradient_norm: 1.210/32 [========>.....................] - ETA: 4s - det_loss: 0.2184 - cls_loss: 0.2083 - box_loss: 2.0072e-04 - reg_l2_loss: 0.0635 - loss: 0.2819 - learning_rate: 1.4770e-04 - gradient_norm: 1.311/32 [=========>....................] - ETA: 4s - det_loss: 0.2153 - cls_loss: 0.2048 - box_loss: 2.1096e-04 - reg_l2_loss: 0.0635 - loss: 0.2789 - learning_rate: 1.4532e-04 - gradient_norm: 1.312/32 [==========>...................] - ETA: 4s - det_loss: 0.2210 - cls_loss: 0.2097 - box_loss: 2.2728e-04 - reg_l2_loss: 0.0635 - loss: 0.2846 - learning_rate: 1.4296e-04 - gradient_norm: 1.413/32 [===========>..................] - ETA: 4s - det_loss: 0.2241 - cls_loss: 0.2130 - box_loss: 2.2233e-04 - reg_l2_loss: 0.0635 - loss: 0.2876 - learning_rate: 1.4064e-04 - gradient_norm: 1.414/32 [============>.................] - ETA: 3s - det_loss: 0.2190 - cls_loss: 0.2080 - box_loss: 2.1990e-04 - reg_l2_loss: 0.0635 - loss: 0.2825 - learning_rate: 1.3833e-04 - gradient_norm: 1.415/32 [=============>................] - ETA: 3s - det_loss: 0.2177 - cls_loss: 0.2068 - box_loss: 2.1840e-04 - reg_l2_loss: 0.0635 - loss: 0.2813 - learning_rate: 1.3606e-04 - gradient_norm: 1.416/32 [==============>...............] - ETA: 3s - det_loss: 0.2171 - cls_loss: 0.2064 - box_loss: 2.1385e-04 - reg_l2_loss: 0.0635 - loss: 0.2807 - learning_rate: 1.3381e-04 - gradient_norm: 1.417/32 [==============>...............] - ETA: 3s - det_loss: 0.2164 - cls_loss: 0.2060 - box_loss: 2.0798e-04 - reg_l2_loss: 0.0635 - loss: 0.2799 - learning_rate: 1.3159e-04 - gradient_norm: 1.418/32 [===============>..............] - ETA: 3s - det_loss: 0.2169 - cls_loss: 0.2065 - box_loss: 2.0783e-04 - reg_l2_loss: 0.0635 - loss: 0.2804 - learning_rate: 1.2940e-04 - gradient_norm: 1.419/32 [================>.............] - ETA: 2s - det_loss: 0.2136 - cls_loss: 0.2032 - box_loss: 2.0619e-04 - reg_l2_loss: 0.0635 - loss: 0.2771 - learning_rate: 1.2723e-04 - gradient_norm: 1.420/32 [=================>............] - ETA: 2s - det_loss: 0.2216 - cls_loss: 0.2114 - box_loss: 2.0317e-04 - reg_l2_loss: 0.0635 - loss: 0.2851 - learning_rate: 1.2510e-04 - gradient_norm: 1.521/32 [==================>...........] - ETA: 2s - det_loss: 0.2188 - cls_loss: 0.2086 - box_loss: 2.0284e-04 - reg_l2_loss: 0.0635 - loss: 0.2823 - learning_rate: 1.2299e-04 - gradient_norm: 1.522/32 [===================>..........] - ETA: 2s - det_loss: 0.2184 - cls_loss: 0.2080 - box_loss: 2.0694e-04 - reg_l2_loss: 0.0635 - loss: 0.2819 - learning_rate: 1.2090e-04 - gradient_norm: 1.523/32 [====================>.........] - ETA: 1s - det_loss: 0.2168 - cls_loss: 0.2066 - box_loss: 2.0365e-04 - reg_l2_loss: 0.0635 - loss: 0.2803 - learning_rate: 1.1885e-04 - gradient_norm: 1.424/32 [=====================>........] - ETA: 1s - det_loss: 0.2182 - cls_loss: 0.2080 - box_loss: 2.0306e-04 - reg_l2_loss: 0.0635 - loss: 0.2817 - learning_rate: 1.1682e-04 - gradient_norm: 1.525/32 [======================>.......] - ETA: 1s - det_loss: 0.2180 - cls_loss: 0.2079 - box_loss: 2.0355e-04 - reg_l2_loss: 0.0635 - loss: 0.2816 - learning_rate: 1.1482e-04 - gradient_norm: 1.526/32 [=======================>......] - ETA: 1s - det_loss: 0.2185 - cls_loss: 0.2082 - box_loss: 2.0545e-04 - reg_l2_loss: 0.0635 - loss: 0.2820 - learning_rate: 1.1284e-04 - gradient_norm: 1.527/32 [========================>.....] - ETA: 1s - det_loss: 0.2189 - cls_loss: 0.2086 - box_loss: 2.0560e-04 - reg_l2_loss: 0.0635 - loss: 0.2824 - learning_rate: 1.1090e-04 - gradient_norm: 1.628/32 [=========================>....] - ETA: 0s - det_loss: 0.2178 - cls_loss: 0.2077 - box_loss: 2.0230e-04 - reg_l2_loss: 0.0635 - loss: 0.2814 - learning_rate: 1.0898e-04 - gradient_norm: 1.629/32 [==========================>...] - ETA: 0s - det_loss: 0.2182 - cls_loss: 0.2082 - box_loss: 1.9997e-04 - reg_l2_loss: 0.0635 - loss: 0.2817 - learning_rate: 1.0708e-04 - gradient_norm: 1.630/32 [===========================>..] - ETA: 0s - det_loss: 0.2161 - cls_loss: 0.2062 - box_loss: 1.9819e-04 - reg_l2_loss: 0.0635 - loss: 0.2796 - learning_rate: 1.0522e-04 - gradient_norm: 1.631/32 [============================>.] - ETA: 0s - det_loss: 0.2188 - cls_loss: 0.2086 - box_loss: 2.0417e-04 - reg_l2_loss: 0.0635 - loss: 0.2823 - learning_rate: 1.0338e-04 - gradient_norm: 1.632/32 [==============================] - ETA: 0s - det_loss: 0.2185 - cls_loss: 0.2084 - box_loss: 2.0220e-04 - reg_l2_loss: 0.0635 - loss: 0.2821 - learning_rate: 1.0157e-04 - gradient_norm: 1.632/32 [==============================] - 9s 280ms/step - det_loss: 0.2183 - cls_loss: 0.2083 - box_loss: 2.0036e-04 - reg_l2_loss: 0.0635 - loss: 0.2819 - learning_rate: 9.9875e-05 - gradient_norm: 1.5951 - val_det_loss: 0.2610 - val_cls_loss: 0.2526 - val_box_loss: 1.6666e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3245
Epoch 24/25
 1/32 [..............................] - ETA: 6s - det_loss: 0.2214 - cls_loss: 0.2144 - box_loss: 1.4135e-04 - reg_l2_loss: 0.0635 - loss: 0.2850 - learning_rate: 4.2776e-05 - gradient_norm: 0.7 2/32 [>.............................] - ETA: 6s - det_loss: 0.2094 - cls_loss: 0.2031 - box_loss: 1.2546e-04 - reg_l2_loss: 0.0635 - loss: 0.2729 - learning_rate: 4.1462e-05 - gradient_norm: 0.9 3/32 [=>............................] - ETA: 6s - det_loss: 0.1970 - cls_loss: 0.1903 - box_loss: 1.3494e-04 - reg_l2_loss: 0.0635 - loss: 0.2605 - learning_rate: 4.0175e-05 - gradient_norm: 1.2 4/32 [==>...........................] - ETA: 6s - det_loss: 0.2175 - cls_loss: 0.2110 - box_loss: 1.3018e-04 - reg_l2_loss: 0.0635 - loss: 0.2810 - learning_rate: 3.8917e-05 - gradient_norm: 1.2 5/32 [===>..........................] - ETA: 5s - det_loss: 0.2069 - cls_loss: 0.2002 - box_loss: 1.3359e-04 - reg_l2_loss: 0.0635 - loss: 0.2704 - learning_rate: 3.7685e-05 - gradient_norm: 1.2 6/32 [====>.........................] - ETA: 5s - det_loss: 0.2162 - cls_loss: 0.2090 - box_loss: 1.4595e-04 - reg_l2_loss: 0.0635 - loss: 0.2798 - learning_rate: 3.6482e-05 - gradient_norm: 1.5 7/32 [=====>........................] - ETA: 5s - det_loss: 0.2293 - cls_loss: 0.2216 - box_loss: 1.5345e-04 - reg_l2_loss: 0.0635 - loss: 0.2929 - learning_rate: 3.5306e-05 - gradient_norm: 1.5 8/32 [======>.......................] - ETA: 5s - det_loss: 0.2267 - cls_loss: 0.2182 - box_loss: 1.6958e-04 - reg_l2_loss: 0.0635 - loss: 0.2902 - learning_rate: 3.4158e-05 - gradient_norm: 1.4 9/32 [=======>......................] - ETA: 5s - det_loss: 0.2224 - cls_loss: 0.2139 - box_loss: 1.7130e-04 - reg_l2_loss: 0.0635 - loss: 0.2860 - learning_rate: 3.3038e-05 - gradient_norm: 1.410/32 [========>.....................] - ETA: 4s - det_loss: 0.2247 - cls_loss: 0.2162 - box_loss: 1.6875e-04 - reg_l2_loss: 0.0635 - loss: 0.2882 - learning_rate: 3.1946e-05 - gradient_norm: 1.511/32 [=========>....................] - ETA: 4s - det_loss: 0.2264 - cls_loss: 0.2179 - box_loss: 1.6825e-04 - reg_l2_loss: 0.0635 - loss: 0.2899 - learning_rate: 3.0881e-05 - gradient_norm: 1.512/32 [==========>...................] - ETA: 4s - det_loss: 0.2252 - cls_loss: 0.2167 - box_loss: 1.7059e-04 - reg_l2_loss: 0.0635 - loss: 0.2887 - learning_rate: 2.9844e-05 - gradient_norm: 1.513/32 [===========>..................] - ETA: 4s - det_loss: 0.2228 - cls_loss: 0.2144 - box_loss: 1.6763e-04 - reg_l2_loss: 0.0635 - loss: 0.2864 - learning_rate: 2.8835e-05 - gradient_norm: 1.614/32 [============>.................] - ETA: 4s - det_loss: 0.2217 - cls_loss: 0.2133 - box_loss: 1.6844e-04 - reg_l2_loss: 0.0635 - loss: 0.2853 - learning_rate: 2.7853e-05 - gradient_norm: 1.615/32 [=============>................] - ETA: 3s - det_loss: 0.2208 - cls_loss: 0.2122 - box_loss: 1.7334e-04 - reg_l2_loss: 0.0635 - loss: 0.2844 - learning_rate: 2.6900e-05 - gradient_norm: 1.516/32 [==============>...............] - ETA: 3s - det_loss: 0.2174 - cls_loss: 0.2087 - box_loss: 1.7264e-04 - reg_l2_loss: 0.0635 - loss: 0.2809 - learning_rate: 2.5974e-05 - gradient_norm: 1.517/32 [==============>...............] - ETA: 3s - det_loss: 0.2163 - cls_loss: 0.2077 - box_loss: 1.7211e-04 - reg_l2_loss: 0.0635 - loss: 0.2798 - learning_rate: 2.5075e-05 - gradient_norm: 1.518/32 [===============>..............] - ETA: 3s - det_loss: 0.2142 - cls_loss: 0.2053 - box_loss: 1.7773e-04 - reg_l2_loss: 0.0635 - loss: 0.2777 - learning_rate: 2.4205e-05 - gradient_norm: 1.519/32 [================>.............] - ETA: 2s - det_loss: 0.2143 - cls_loss: 0.2051 - box_loss: 1.8411e-04 - reg_l2_loss: 0.0635 - loss: 0.2779 - learning_rate: 2.3363e-05 - gradient_norm: 1.520/32 [=================>............] - ETA: 2s - det_loss: 0.2132 - cls_loss: 0.2041 - box_loss: 1.8186e-04 - reg_l2_loss: 0.0635 - loss: 0.2768 - learning_rate: 2.2548e-05 - gradient_norm: 1.521/32 [==================>...........] - ETA: 2s - det_loss: 0.2142 - cls_loss: 0.2050 - box_loss: 1.8418e-04 - reg_l2_loss: 0.0635 - loss: 0.2777 - learning_rate: 2.1761e-05 - gradient_norm: 1.422/32 [===================>..........] - ETA: 2s - det_loss: 0.2179 - cls_loss: 0.2087 - box_loss: 1.8377e-04 - reg_l2_loss: 0.0635 - loss: 0.2814 - learning_rate: 2.1002e-05 - gradient_norm: 1.523/32 [====================>.........] - ETA: 2s - det_loss: 0.2157 - cls_loss: 0.2064 - box_loss: 1.8607e-04 - reg_l2_loss: 0.0635 - loss: 0.2793 - learning_rate: 2.0271e-05 - gradient_norm: 1.524/32 [=====================>........] - ETA: 1s - det_loss: 0.2130 - cls_loss: 0.2037 - box_loss: 1.8506e-04 - reg_l2_loss: 0.0635 - loss: 0.2765 - learning_rate: 1.9567e-05 - gradient_norm: 1.425/32 [======================>.......] - ETA: 1s - det_loss: 0.2109 - cls_loss: 0.2016 - box_loss: 1.8481e-04 - reg_l2_loss: 0.0635 - loss: 0.2744 - learning_rate: 1.8892e-05 - gradient_norm: 1.426/32 [=======================>......] - ETA: 1s - det_loss: 0.2072 - cls_loss: 0.1980 - box_loss: 1.8515e-04 - reg_l2_loss: 0.0635 - loss: 0.2708 - learning_rate: 1.8244e-05 - gradient_norm: 1.427/32 [========================>.....] - ETA: 1s - det_loss: 0.2075 - cls_loss: 0.1981 - box_loss: 1.8729e-04 - reg_l2_loss: 0.0635 - loss: 0.2710 - learning_rate: 1.7624e-05 - gradient_norm: 1.428/32 [=========================>....] - ETA: 0s - det_loss: 0.2075 - cls_loss: 0.1977 - box_loss: 1.9566e-04 - reg_l2_loss: 0.0635 - loss: 0.2711 - learning_rate: 1.7032e-05 - gradient_norm: 1.429/32 [==========================>...] - ETA: 0s - det_loss: 0.2053 - cls_loss: 0.1956 - box_loss: 1.9510e-04 - reg_l2_loss: 0.0635 - loss: 0.2689 - learning_rate: 1.6468e-05 - gradient_norm: 1.430/32 [===========================>..] - ETA: 0s - det_loss: 0.2087 - cls_loss: 0.1987 - box_loss: 2.0073e-04 - reg_l2_loss: 0.0635 - loss: 0.2723 - learning_rate: 1.5931e-05 - gradient_norm: 1.431/32 [============================>.] - ETA: 0s - det_loss: 0.2114 - cls_loss: 0.2013 - box_loss: 2.0153e-04 - reg_l2_loss: 0.0635 - loss: 0.2749 - learning_rate: 1.5423e-05 - gradient_norm: 1.432/32 [==============================] - ETA: 0s - det_loss: 0.2112 - cls_loss: 0.2012 - box_loss: 2.0103e-04 - reg_l2_loss: 0.0635 - loss: 0.2748 - learning_rate: 1.4942e-05 - gradient_norm: 1.432/32 [==============================] - 9s 287ms/step - det_loss: 0.2111 - cls_loss: 0.2010 - box_loss: 2.0055e-04 - reg_l2_loss: 0.0635 - loss: 0.2746 - learning_rate: 1.4490e-05 - gradient_norm: 1.4639 - val_det_loss: 0.2614 - val_cls_loss: 0.2531 - val_box_loss: 1.6715e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3250
Epoch 25/25
 1/32 [..............................] - ETA: 6s - det_loss: 0.2392 - cls_loss: 0.2265 - box_loss: 2.5451e-04 - reg_l2_loss: 0.0635 - loss: 0.3027 - learning_rate: 0.0000e+00 - gradient_norm: 0.9 2/32 [>.............................] - ETA: 6s - det_loss: 0.2093 - cls_loss: 0.1973 - box_loss: 2.4092e-04 - reg_l2_loss: 0.0635 - loss: 0.2729 - learning_rate: 2.0862e-08 - gradient_norm: 1.3 3/32 [=>............................] - ETA: 6s - det_loss: 0.2374 - cls_loss: 0.2216 - box_loss: 3.1713e-04 - reg_l2_loss: 0.0635 - loss: 0.3010 - learning_rate: 6.9638e-08 - gradient_norm: 1.3 4/32 [==>...........................] - ETA: 6s - det_loss: 0.2257 - cls_loss: 0.2116 - box_loss: 2.8209e-04 - reg_l2_loss: 0.0635 - loss: 0.2892 - learning_rate: 1.4633e-07 - gradient_norm: 1.4 5/32 [===>..........................] - ETA: 5s - det_loss: 0.2248 - cls_loss: 0.2101 - box_loss: 2.9523e-04 - reg_l2_loss: 0.0635 - loss: 0.2884 - learning_rate: 2.5094e-07 - gradient_norm: 1.4 6/32 [====>.........................] - ETA: 5s - det_loss: 0.2231 - cls_loss: 0.2095 - box_loss: 2.7104e-04 - reg_l2_loss: 0.0635 - loss: 0.2866 - learning_rate: 3.8341e-07 - gradient_norm: 1.4 7/32 [=====>........................] - ETA: 5s - det_loss: 0.2127 - cls_loss: 0.1999 - box_loss: 2.5623e-04 - reg_l2_loss: 0.0635 - loss: 0.2763 - learning_rate: 5.4376e-07 - gradient_norm: 1.5 8/32 [======>.......................] - ETA: 5s - det_loss: 0.2081 - cls_loss: 0.1956 - box_loss: 2.4921e-04 - reg_l2_loss: 0.0635 - loss: 0.2716 - learning_rate: 7.3202e-07 - gradient_norm: 1.5 9/32 [=======>......................] - ETA: 4s - det_loss: 0.2012 - cls_loss: 0.1893 - box_loss: 2.3852e-04 - reg_l2_loss: 0.0635 - loss: 0.2647 - learning_rate: 9.4814e-07 - gradient_norm: 1.410/32 [========>.....................] - ETA: 4s - det_loss: 0.1983 - cls_loss: 0.1868 - box_loss: 2.2986e-04 - reg_l2_loss: 0.0635 - loss: 0.2618 - learning_rate: 1.1922e-06 - gradient_norm: 1.311/32 [=========>....................] - ETA: 4s - det_loss: 0.1996 - cls_loss: 0.1883 - box_loss: 2.2467e-04 - reg_l2_loss: 0.0635 - loss: 0.2631 - learning_rate: 1.4640e-06 - gradient_norm: 1.312/32 [==========>...................] - ETA: 4s - det_loss: 0.1981 - cls_loss: 0.1857 - box_loss: 2.4653e-04 - reg_l2_loss: 0.0635 - loss: 0.2616 - learning_rate: 1.7638e-06 - gradient_norm: 1.313/32 [===========>..................] - ETA: 4s - det_loss: 0.1995 - cls_loss: 0.1871 - box_loss: 2.4824e-04 - reg_l2_loss: 0.0635 - loss: 0.2631 - learning_rate: 2.0914e-06 - gradient_norm: 1.314/32 [============>.................] - ETA: 3s - det_loss: 0.2016 - cls_loss: 0.1892 - box_loss: 2.4767e-04 - reg_l2_loss: 0.0635 - loss: 0.2651 - learning_rate: 2.4469e-06 - gradient_norm: 1.315/32 [=============>................] - ETA: 3s - det_loss: 0.2075 - cls_loss: 0.1952 - box_loss: 2.4536e-04 - reg_l2_loss: 0.0635 - loss: 0.2710 - learning_rate: 2.8302e-06 - gradient_norm: 1.316/32 [==============>...............] - ETA: 3s - det_loss: 0.2056 - cls_loss: 0.1935 - box_loss: 2.4155e-04 - reg_l2_loss: 0.0635 - loss: 0.2691 - learning_rate: 3.2414e-06 - gradient_norm: 1.317/32 [==============>...............] - ETA: 3s - det_loss: 0.2035 - cls_loss: 0.1917 - box_loss: 2.3499e-04 - reg_l2_loss: 0.0635 - loss: 0.2670 - learning_rate: 3.6805e-06 - gradient_norm: 1.218/32 [===============>..............] - ETA: 3s - det_loss: 0.2009 - cls_loss: 0.1893 - box_loss: 2.3180e-04 - reg_l2_loss: 0.0635 - loss: 0.2644 - learning_rate: 4.1474e-06 - gradient_norm: 1.219/32 [================>.............] - ETA: 2s - det_loss: 0.2003 - cls_loss: 0.1889 - box_loss: 2.2699e-04 - reg_l2_loss: 0.0635 - loss: 0.2638 - learning_rate: 4.6422e-06 - gradient_norm: 1.220/32 [=================>............] - ETA: 2s - det_loss: 0.2000 - cls_loss: 0.1887 - box_loss: 2.2614e-04 - reg_l2_loss: 0.0635 - loss: 0.2635 - learning_rate: 5.1648e-06 - gradient_norm: 1.321/32 [==================>...........] - ETA: 2s - det_loss: 0.1995 - cls_loss: 0.1884 - box_loss: 2.2314e-04 - reg_l2_loss: 0.0635 - loss: 0.2631 - learning_rate: 5.7152e-06 - gradient_norm: 1.322/32 [===================>..........] - ETA: 2s - det_loss: 0.1998 - cls_loss: 0.1887 - box_loss: 2.2028e-04 - reg_l2_loss: 0.0635 - loss: 0.2633 - learning_rate: 6.2935e-06 - gradient_norm: 1.323/32 [====================>.........] - ETA: 2s - det_loss: 0.2043 - cls_loss: 0.1933 - box_loss: 2.1904e-04 - reg_l2_loss: 0.0635 - loss: 0.2678 - learning_rate: 6.8995e-06 - gradient_norm: 1.324/32 [=====================>........] - ETA: 1s - det_loss: 0.2076 - cls_loss: 0.1966 - box_loss: 2.2019e-04 - reg_l2_loss: 0.0635 - loss: 0.2711 - learning_rate: 7.5335e-06 - gradient_norm: 1.325/32 [======================>.......] - ETA: 1s - det_loss: 0.2060 - cls_loss: 0.1952 - box_loss: 2.1593e-04 - reg_l2_loss: 0.0635 - loss: 0.2695 - learning_rate: 8.1952e-06 - gradient_norm: 1.326/32 [=======================>......] - ETA: 1s - det_loss: 0.2083 - cls_loss: 0.1976 - box_loss: 2.1380e-04 - reg_l2_loss: 0.0635 - loss: 0.2718 - learning_rate: 8.8847e-06 - gradient_norm: 1.327/32 [========================>.....] - ETA: 1s - det_loss: 0.2075 - cls_loss: 0.1969 - box_loss: 2.1209e-04 - reg_l2_loss: 0.0635 - loss: 0.2710 - learning_rate: 9.6020e-06 - gradient_norm: 1.328/32 [=========================>....] - ETA: 0s - det_loss: 0.2067 - cls_loss: 0.1962 - box_loss: 2.0998e-04 - reg_l2_loss: 0.0635 - loss: 0.2703 - learning_rate: 1.0347e-05 - gradient_norm: 1.229/32 [==========================>...] - ETA: 0s - det_loss: 0.2049 - cls_loss: 0.1944 - box_loss: 2.0912e-04 - reg_l2_loss: 0.0635 - loss: 0.2684 - learning_rate: 1.1120e-05 - gradient_norm: 1.230/32 [===========================>..] - ETA: 0s - det_loss: 0.2074 - cls_loss: 0.1970 - box_loss: 2.0747e-04 - reg_l2_loss: 0.0635 - loss: 0.2709 - learning_rate: 1.1921e-05 - gradient_norm: 1.331/32 [============================>.] - ETA: 0s - det_loss: 0.2090 - cls_loss: 0.1988 - box_loss: 2.0514e-04 - reg_l2_loss: 0.0635 - loss: 0.2725 - learning_rate: 1.2749e-05 - gradient_norm: 1.232/32 [==============================] - ETA: 0s - det_loss: 0.2107 - cls_loss: 0.2002 - box_loss: 2.0904e-04 - reg_l2_loss: 0.0635 - loss: 0.2742 - learning_rate: 1.3605e-05 - gradient_norm: 1.332/32 [==============================] - 10s 326ms/step - det_loss: 0.2123 - cls_loss: 0.2016 - box_loss: 2.1270e-04 - reg_l2_loss: 0.0635 - loss: 0.2758 - learning_rate: 1.4410e-05 - gradient_norm: 1.3390 - val_det_loss: 0.2598 - val_cls_loss: 0.2516 - val_box_loss: 1.6422e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.3234
=============Validation results==============

2023-03-31 03:11:52.939079: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2/2 [==============================] - 12s 3s/step

{'AP': 0.54263425, 'AP50': 0.61447525, 'AP75': 0.58470213, 'APs': -1.0, 'APm': -1.0, 'APl': 0.54263633, 'ARmax1': 0.79817504, 'ARmax10': 0.81626713, 'ARmax100': 0.81626713, 'ARs': -1.0, 'ARm': -1.0, 'ARl': 0.81626713, 'AP_/clear': 0.9429993, 'AP_/left': 0.30667418, 'AP_/right': 0.3576661, 'AP_/center': 0.56319743}
=============Test results==============

2/2 [==============================] - 12s 4s/step

{'AP': 0.4560794, 'AP50': 0.5289358, 'AP75': 0.51136374, 'APs': -1.0, 'APm': -1.0, 'APl': 0.45608687, 'ARmax1': 0.70564073, 'ARmax10': 0.72709954, 'ARmax100': 0.72973114, 'ARs': -1.0, 'ARm': -1.0, 'ARl': 0.72973114, 'AP_/clear': 0.90452003, 'AP_/left': 0.2696766, 'AP_/right': 0.32626432, 'AP_/center': 0.32385662}
2023-03-31 03:12:11.623553: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2023-03-31 03:12:31.444146: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.
2023-03-31 03:12:36.718998: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.
2023-03-31 03:12:36.719037: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.
2023-03-31 03:12:36.719756: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp9ilyb1ss
2023-03-31 03:12:36.817907: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }
2023-03-31 03:12:36.817948: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmp9ilyb1ss
2023-03-31 03:12:37.138073: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2023-03-31 03:12:38.846697: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmp9ilyb1ss
2023-03-31 03:12:39.537286: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2817534 microseconds.
2023-03-31 03:12:40.625764: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-31 03:12:41.938472: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs

Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs
fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0
2023-03-31 03:13:24.562737: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs

Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs


Done with model of batch size 8 and epoch 25
