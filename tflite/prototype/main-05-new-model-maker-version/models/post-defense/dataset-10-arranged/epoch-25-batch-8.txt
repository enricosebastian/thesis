(new-model-maker) enricosebastian@enricosebastian-MS-7A66:~/Desktop/thesis/tflite/prototype/main-05-new-model-maker-version$ /home/enricosebastian/miniconda3/envs/new-model-maker/bin/python /home/enricosebastian/Desktop/thesis/tflite/prototype/main-05-new-model-maker-version/model-maker.py
/home/enricosebastian/miniconda3/envs/new-model-maker/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.9.0 and strictly below 2.12.0 (nightly versions are not supported). 
 The versions of TensorFlow you are currently using is 2.8.4 and is not supported. 
Some things might work, some things might not.
If you were to encounter a bug, do not file an issue.
If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. 
You can find the compatibility matrix in TensorFlow Addon's readme:
https://github.com/tensorflow/addons
  warnings.warn(
2023-03-31 06:07:49.307703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.313735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.313945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.314454: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-03-31 06:07:49.315004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.315249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.315417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.722852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.723127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.723294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2023-03-31 06:07:49.723438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5054 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1
Epoch 1/25
2023-03-31 06:08:15.701843: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100
2023-03-31 06:08:15.912475: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-03-31 06:08:15.913147: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-03-31 06:08:15.913171: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Couldn't invoke ptxas --version
2023-03-31 06:08:15.913785: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2023-03-31 06:08:15.913837: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: Failed to launch ptxas
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
44/44 [==============================] - 33s 295ms/step - det_loss: 1.5574 - cls_loss: 1.1025 - box_loss: 0.0091 - reg_l2_loss: 0.0633 - loss: 1.6207 - learning_rate: 0.0090 - gradient_norm: 1.4395 - val_det_loss: 1.5282 - val_cls_loss: 1.0342 - val_box_loss: 0.0099 - val_reg_l2_loss: 0.0634 - val_loss: 1.5915
Epoch 2/25
44/44 [==============================] - 11s 247ms/step - det_loss: 0.9368 - cls_loss: 0.7364 - box_loss: 0.0040 - reg_l2_loss: 0.0634 - loss: 1.0002 - learning_rate: 0.0099 - gradient_norm: 1.8249 - val_det_loss: 1.7889 - val_cls_loss: 1.2586 - val_box_loss: 0.0106 - val_reg_l2_loss: 0.0634 - val_loss: 1.8523
Epoch 3/25
44/44 [==============================] - 11s 250ms/step - det_loss: 0.5435 - cls_loss: 0.4706 - box_loss: 0.0015 - reg_l2_loss: 0.0635 - loss: 0.6070 - learning_rate: 0.0097 - gradient_norm: 1.5030 - val_det_loss: 1.1456 - val_cls_loss: 0.6571 - val_box_loss: 0.0098 - val_reg_l2_loss: 0.0635 - val_loss: 1.2091
Epoch 4/25
44/44 [==============================] - 11s 248ms/step - det_loss: 0.4325 - cls_loss: 0.3948 - box_loss: 7.5478e-04 - reg_l2_loss: 0.0635 - loss: 0.4960 - learning_rate: 0.0095 - gradient_norm: 1.1867 - val_det_loss: 0.9049 - val_cls_loss: 0.5027 - val_box_loss: 0.0080 - val_reg_l2_loss: 0.0635 - val_loss: 0.9684
Epoch 5/25
44/44 [==============================] - 15s 355ms/step - det_loss: 0.4003 - cls_loss: 0.3698 - box_loss: 6.0871e-04 - reg_l2_loss: 0.0635 - loss: 0.4638 - learning_rate: 0.0092 - gradient_norm: 1.4819 - val_det_loss: 1.1018 - val_cls_loss: 0.5913 - val_box_loss: 0.0102 - val_reg_l2_loss: 0.0635 - val_loss: 1.1653
Epoch 6/25
44/44 [==============================] - 11s 251ms/step - det_loss: 0.3559 - cls_loss: 0.3321 - box_loss: 4.7688e-04 - reg_l2_loss: 0.0635 - loss: 0.4194 - learning_rate: 0.0088 - gradient_norm: 1.1512 - val_det_loss: 1.3099 - val_cls_loss: 0.7672 - val_box_loss: 0.0109 - val_reg_l2_loss: 0.0635 - val_loss: 1.3734
Epoch 7/25
44/44 [==============================] - 11s 253ms/step - det_loss: 0.3199 - cls_loss: 0.3013 - box_loss: 3.7347e-04 - reg_l2_loss: 0.0635 - loss: 0.3834 - learning_rate: 0.0083 - gradient_norm: 1.2373 - val_det_loss: 0.8456 - val_cls_loss: 0.4922 - val_box_loss: 0.0071 - val_reg_l2_loss: 0.0635 - val_loss: 0.9091
Epoch 8/25
44/44 [==============================] - 11s 259ms/step - det_loss: 0.3114 - cls_loss: 0.2926 - box_loss: 3.7710e-04 - reg_l2_loss: 0.0635 - loss: 0.3749 - learning_rate: 0.0078 - gradient_norm: 1.7012 - val_det_loss: 1.0209 - val_cls_loss: 0.5179 - val_box_loss: 0.0101 - val_reg_l2_loss: 0.0635 - val_loss: 1.0845
Epoch 9/25
44/44 [==============================] - 11s 253ms/step - det_loss: 0.2947 - cls_loss: 0.2793 - box_loss: 3.0705e-04 - reg_l2_loss: 0.0635 - loss: 0.3582 - learning_rate: 0.0072 - gradient_norm: 1.6015 - val_det_loss: 1.2012 - val_cls_loss: 0.6092 - val_box_loss: 0.0118 - val_reg_l2_loss: 0.0635 - val_loss: 1.2647
Epoch 10/25
44/44 [==============================] - 12s 279ms/step - det_loss: 0.2828 - cls_loss: 0.2673 - box_loss: 3.0955e-04 - reg_l2_loss: 0.0635 - loss: 0.3463 - learning_rate: 0.0066 - gradient_norm: 1.4987 - val_det_loss: 0.5867 - val_cls_loss: 0.4145 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0635 - val_loss: 0.6502
Epoch 11/25
44/44 [==============================] - 11s 253ms/step - det_loss: 0.2667 - cls_loss: 0.2523 - box_loss: 2.8792e-04 - reg_l2_loss: 0.0635 - loss: 0.3303 - learning_rate: 0.0060 - gradient_norm: 1.2737 - val_det_loss: 0.3654 - val_cls_loss: 0.3208 - val_box_loss: 8.9266e-04 - val_reg_l2_loss: 0.0635 - val_loss: 0.4290
Epoch 12/25
44/44 [==============================] - 11s 257ms/step - det_loss: 0.2566 - cls_loss: 0.2445 - box_loss: 2.4215e-04 - reg_l2_loss: 0.0635 - loss: 0.3202 - learning_rate: 0.0053 - gradient_norm: 1.4867 - val_det_loss: 0.3880 - val_cls_loss: 0.3790 - val_box_loss: 1.7986e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.4515
Epoch 13/25
44/44 [==============================] - 11s 253ms/step - det_loss: 0.2477 - cls_loss: 0.2360 - box_loss: 2.3407e-04 - reg_l2_loss: 0.0636 - loss: 0.3112 - learning_rate: 0.0047 - gradient_norm: 1.5411 - val_det_loss: 0.3264 - val_cls_loss: 0.2975 - val_box_loss: 5.7953e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3900
Epoch 14/25
44/44 [==============================] - 11s 251ms/step - det_loss: 0.2373 - cls_loss: 0.2269 - box_loss: 2.0830e-04 - reg_l2_loss: 0.0636 - loss: 0.3009 - learning_rate: 0.0040 - gradient_norm: 1.5073 - val_det_loss: 0.2938 - val_cls_loss: 0.2861 - val_box_loss: 1.5482e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3574
Epoch 15/25
44/44 [==============================] - 12s 281ms/step - det_loss: 0.2284 - cls_loss: 0.2189 - box_loss: 1.8898e-04 - reg_l2_loss: 0.0636 - loss: 0.2920 - learning_rate: 0.0034 - gradient_norm: 1.4088 - val_det_loss: 0.3081 - val_cls_loss: 0.2867 - val_box_loss: 4.2906e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3717
Epoch 16/25
44/44 [==============================] - 11s 259ms/step - det_loss: 0.2129 - cls_loss: 0.2040 - box_loss: 1.7920e-04 - reg_l2_loss: 0.0636 - loss: 0.2765 - learning_rate: 0.0028 - gradient_norm: 1.5615 - val_det_loss: 0.3153 - val_cls_loss: 0.3092 - val_box_loss: 1.2194e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3789
Epoch 17/25
44/44 [==============================] - 11s 251ms/step - det_loss: 0.2120 - cls_loss: 0.2035 - box_loss: 1.6973e-04 - reg_l2_loss: 0.0636 - loss: 0.2756 - learning_rate: 0.0022 - gradient_norm: 1.5688 - val_det_loss: 0.3109 - val_cls_loss: 0.3047 - val_box_loss: 1.2312e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3745
Epoch 18/25
44/44 [==============================] - 11s 253ms/step - det_loss: 0.2079 - cls_loss: 0.1991 - box_loss: 1.7516e-04 - reg_l2_loss: 0.0636 - loss: 0.2715 - learning_rate: 0.0017 - gradient_norm: 1.6088 - val_det_loss: 0.3223 - val_cls_loss: 0.3169 - val_box_loss: 1.0790e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3859
Epoch 19/25
44/44 [==============================] - 11s 255ms/step - det_loss: 0.2095 - cls_loss: 0.2013 - box_loss: 1.6406e-04 - reg_l2_loss: 0.0636 - loss: 0.2730 - learning_rate: 0.0012 - gradient_norm: 1.6756 - val_det_loss: 0.3378 - val_cls_loss: 0.3328 - val_box_loss: 1.0091e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.4014
Epoch 20/25
 9/44 [=====>........................] - ETA: 7s - det_loss: 0.2187 - cls_loss: 0.2089 - box_loss: 1.9775e-04 - reg_l2_loss: 0.0636 - loss: 0.2823 - learning_rate: 9.9741e-04 - gradient_norm: 1.410/44 [=====>........................] - ETA: 7s - det_loss: 0.2130 - cls_loss: 0.2027 - box_loss: 2.0505e-04 - reg_l2_loss: 0.0636 - loss: 0.2766 - learning_rate: 9.9299e-04 - gradient_norm: 1.411/44 [======>.......................] - ETA: 7s - det_loss: 0.2155 - cls_loss: 0.2055 - box_loss: 2.0036e-04 - reg_l2_loss: 0.0636 - loss: 0.2790 - learning_rate: 9.8857e-04 - gradient_norm: 1.512/44 [=======>......................] - ETA: 6s - det_loss: 0.2130 - cls_loss: 0.2035 - box_loss: 1.9059e-04 - reg_l2_loss: 0.0636 - loss: 0.2766 - learning_rate: 9.8417e-04 - gradient_norm: 1.513/44 [=======>......................] - ETA: 6s - det_loss: 0.2119 - cls_loss: 0.2025 - box_loss: 1.8763e-04 - reg_l2_loss: 0.0636 - loss: 0.2754 - learning_rate: 9.7979e-04 - gradient_norm: 1.414/44 [========>.....................] - ETA: 6s - det_loss: 0.2103 - cls_loss: 0.2011 - box_loss: 1.8338e-04 - reg_l2_loss: 0.0636 - loss: 0.2738 - learning_rate: 9.7541e-04 - gradient_norm: 1.515/44 [=========>....................] - ETA: 6s - det_loss: 0.2165 - cls_loss: 0.2073 - box_loss: 1.8501e-04 - reg_l2_loss: 0.0636 - loss: 0.2801 - learning_rate: 9.7104e-04 - gradient_norm: 1.516/44 [=========>....................] - ETA: 6s - det_loss: 0.2173 - cls_loss: 0.2082 - box_loss: 1.8185e-04 - reg_l2_loss: 0.0636 - loss: 0.2808 - learning_rate: 9.6669e-04 - gradient_norm: 1.617/44 [==========>...................] - ETA: 5s - det_loss: 0.2164 - cls_loss: 0.2076 - box_loss: 1.7652e-04 - reg_l2_loss: 0.0636 - loss: 0.2800 - learning_rate: 9.6235e-04 - gradient_norm: 1.618/44 [===========>..................] - ETA: 5s - det_loss: 0.2155 - cls_loss: 0.2069 - box_loss: 1.7321e-04 - reg_l2_loss: 0.0636 - loss: 0.2791 - learning_rate: 9.5802e-04 - gradient_norm: 1.619/44 [===========>..................] - ETA: 5s - det_loss: 0.2130 - cls_loss: 0.2044 - box_loss: 1.7243e-04 - reg_l2_loss: 0.0636 - loss: 0.2765 - learning_rate: 9.5370e-04 - gradient_norm: 1.620/44 [============>.................] - ETA: 5s - det_loss: 0.2115 - cls_loss: 0.2030 - box_loss: 1.7123e-04 - reg_l2_loss: 0.0636 - loss: 0.2751 - learning_rate: 9.4940e-04 - gradient_norm: 1.621/44 [=============>................] - ETA: 5s - det_loss: 0.2121 - cls_loss: 0.2037 - box_loss: 1.6861e-04 - reg_l2_loss: 0.0636 - loss: 0.2757 - learning_rate: 9.4511e-04 - gradient_norm: 1.622/44 [==============>...............] - ETA: 4s - det_loss: 0.2113 - cls_loss: 0.2030 - box_loss: 1.6651e-04 - reg_l2_loss: 0.0636 - loss: 0.2749 - learning_rate: 9.4083e-04 - gradient_norm: 1.623/44 [==============>...............] - ETA: 4s - det_loss: 0.2121 - cls_loss: 0.2040 - box_loss: 1.6271e-04 - reg_l2_loss: 0.0636 - loss: 0.2757 - learning_rate: 9.3656e-04 - gradient_norm: 1.624/44 [===============>..............] - ETA: 4s - det_loss: 0.2097 - cls_loss: 0.2015 - box_loss: 1.6395e-04 - reg_l2_loss: 0.0636 - loss: 0.2733 - learning_rate: 9.3230e-04 - gradient_norm: 1.525/44 [================>.............] - ETA: 4s - det_loss: 0.2064 - cls_loss: 0.1983 - box_loss: 1.6243e-04 - reg_l2_loss: 0.0636 - loss: 0.2700 - learning_rate: 9.2806e-04 - gradient_norm: 1.526/44 [================>.............] - ETA: 3s - det_loss: 0.2065 - cls_loss: 0.1985 - box_loss: 1.6001e-04 - reg_l2_loss: 0.0636 - loss: 0.2701 - learning_rate: 9.2383e-04 - gradient_norm: 1.527/44 [=================>............] - ETA: 3s - det_loss: 0.2043 - cls_loss: 0.1963 - box_loss: 1.6006e-04 - reg_l2_loss: 0.0636 - loss: 0.2679 - learning_rate: 9.1961e-04 - gradient_norm: 1.528/44 [==================>...........] - ETA: 3s - det_loss: 0.2054 - cls_loss: 0.1974 - box_loss: 1.5948e-04 - reg_l2_loss: 0.0636 - loss: 0.2689 - learning_rate: 9.1540e-04 - gradient_norm: 1.529/44 [==================>...........] - ETA: 3s - det_loss: 0.2033 - cls_loss: 0.1954 - box_loss: 1.5712e-04 - reg_l2_loss: 0.0636 - loss: 0.2668 - learning_rate: 9.1120e-04 - gradient_norm: 1.530/44 [===================>..........] - ETA: 3s - det_loss: 0.2039 - cls_loss: 0.1959 - box_loss: 1.5911e-04 - reg_l2_loss: 0.0636 - loss: 0.2675 - learning_rate: 9.0702e-04 - gradient_norm: 1.531/44 [====================>.........] - ETA: 2s - det_loss: 0.2034 - cls_loss: 0.1956 - box_loss: 1.5730e-04 - reg_l2_loss: 0.0636 - loss: 0.2670 - learning_rate: 9.0285e-04 - gradient_norm: 1.532/44 [====================>.........] - ETA: 2s - det_loss: 0.2043 - cls_loss: 0.1965 - box_loss: 1.5629e-04 - reg_l2_loss: 0.0636 - loss: 0.2679 - learning_rate: 8.9869e-04 - gradient_norm: 1.533/44 [=====================>........] - ETA: 2s - det_loss: 0.2021 - cls_loss: 0.1942 - box_loss: 1.5748e-04 - reg_l2_loss: 0.0636 - loss: 0.2656 - learning_rate: 8.9454e-04 - gradient_norm: 1.534/44 [======================>.......] - ETA: 2s - det_loss: 0.2025 - cls_loss: 0.1946 - box_loss: 1.5884e-04 - reg_l2_loss: 0.0636 - loss: 0.2661 - learning_rate: 8.9041e-04 - gradient_norm: 1.635/44 [======================>.......] - ETA: 1s - det_loss: 0.2022 - cls_loss: 0.1942 - box_loss: 1.6039e-04 - reg_l2_loss: 0.0636 - loss: 0.2658 - learning_rate: 8.8629e-04 - gradient_norm: 1.636/44 [=======================>......] - ETA: 1s - det_loss: 0.2029 - cls_loss: 0.1947 - box_loss: 1.6270e-04 - reg_l2_loss: 0.0636 - loss: 0.2664 - learning_rate: 8.8218e-04 - gradient_norm: 1.637/44 [========================>.....] - ETA: 1s - det_loss: 0.2044 - cls_loss: 0.1963 - box_loss: 1.6125e-04 - reg_l2_loss: 0.0636 - loss: 0.2679 - learning_rate: 8.7808e-04 - gradient_norm: 1.638/44 [========================>.....] - ETA: 1s - det_loss: 0.2039 - cls_loss: 0.1957 - box_loss: 1.6324e-04 - reg_l2_loss: 0.0636 - loss: 0.2675 - learning_rate: 8.7400e-04 - gradient_norm: 1.639/44 [=========================>....] - ETA: 1s - det_loss: 0.2044 - cls_loss: 0.1963 - box_loss: 1.6241e-04 - reg_l2_loss: 0.0636 - loss: 0.2679 - learning_rate: 8.6993e-04 - gradient_norm: 1.640/44 [==========================>...] - ETA: 0s - det_loss: 0.2048 - cls_loss: 0.1967 - box_loss: 1.6129e-04 - reg_l2_loss: 0.0636 - loss: 0.2683 - learning_rate: 8.6587e-04 - gradient_norm: 1.641/44 [==========================>...] - ETA: 0s - det_loss: 0.2052 - cls_loss: 0.1971 - box_loss: 1.6169e-04 - reg_l2_loss: 0.0636 - loss: 0.2688 - learning_rate: 8.6182e-04 - gradient_norm: 1.642/44 [===========================>..] - ETA: 0s - det_loss: 0.2072 - cls_loss: 0.1991 - box_loss: 1.6273e-04 - reg_l2_loss: 0.0636 - loss: 0.2708 - learning_rate: 8.5778e-04 - gradient_norm: 1.743/44 [============================>.] - ETA: 0s - det_loss: 0.2067 - cls_loss: 0.1985 - box_loss: 1.6378e-04 - reg_l2_loss: 0.0636 - loss: 0.2702 - learning_rate: 8.5376e-04 - gradient_norm: 1.744/44 [==============================] - ETA: 0s - det_loss: 0.2071 - cls_loss: 0.1988 - box_loss: 1.6719e-04 - reg_l2_loss: 0.0636 - loss: 0.2707 - learning_rate: 8.4975e-04 - gradient_norm: 1.744/44 [==============================] - 13s 287ms/step - det_loss: 0.2076 - cls_loss: 0.1991 - box_loss: 1.7045e-04 - reg_l2_loss: 0.0636 - loss: 0.2712 - learning_rate: 8.4592e-04 - gradient_norm: 1.7245 - val_det_loss: 0.3206 - val_cls_loss: 0.3156 - val_box_loss: 1.0030e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3841
Epoch 21/25
 1/44 [..............................] - ETA: 9s - det_loss: 0.1863 - cls_loss: 0.1773 - box_loss: 1.7948e-04 - reg_l2_loss: 0.0636 - loss: 0.2499 - learning_rate: 6.6987e-04 - gradient_norm: 1.5 2/44 [>.............................] - ETA: 8s - det_loss: 0.2219 - cls_loss: 0.2115 - box_loss: 2.0988e-04 - reg_l2_loss: 0.0636 - loss: 0.2855 - learning_rate: 6.6616e-04 - gradient_norm: 1.5 3/44 [=>............................] - ETA: 8s - det_loss: 0.2225 - cls_loss: 0.2138 - box_loss: 1.7443e-04 - reg_l2_loss: 0.0636 - loss: 0.2860 - learning_rate: 6.6247e-04 - gradient_norm: 1.7 4/44 [=>............................] - ETA: 8s - det_loss: 0.2250 - cls_loss: 0.2155 - box_loss: 1.8990e-04 - reg_l2_loss: 0.0636 - loss: 0.2885 - learning_rate: 6.5878e-04 - gradient_norm: 1.7 5/44 [==>...........................] - ETA: 8s - det_loss: 0.2159 - cls_loss: 0.2071 - box_loss: 1.7634e-04 - reg_l2_loss: 0.0636 - loss: 0.2795 - learning_rate: 6.5511e-04 - gradient_norm: 1.6 6/44 [===>..........................] - ETA: 8s - det_loss: 0.2146 - cls_loss: 0.2064 - box_loss: 1.6237e-04 - reg_l2_loss: 0.0636 - loss: 0.2781 - learning_rate: 6.5146e-04 - gradient_norm: 1.6 7/44 [===>..........................] - ETA: 8s - det_loss: 0.2123 - cls_loss: 0.2043 - box_loss: 1.6163e-04 - reg_l2_loss: 0.0636 - loss: 0.2759 - learning_rate: 6.4781e-04 - gradient_norm: 1.6 8/44 [====>.........................] - ETA: 7s - det_loss: 0.2103 - cls_loss: 0.2017 - box_loss: 1.7112e-04 - reg_l2_loss: 0.0636 - loss: 0.2738 - learning_rate: 6.4418e-04 - gradient_norm: 1.6 9/44 [=====>........................] - ETA: 7s - det_loss: 0.2099 - cls_loss: 0.2013 - box_loss: 1.7185e-04 - reg_l2_loss: 0.0636 - loss: 0.2735 - learning_rate: 6.4056e-04 - gradient_norm: 1.610/44 [=====>........................] - ETA: 7s - det_loss: 0.2118 - cls_loss: 0.2030 - box_loss: 1.7640e-04 - reg_l2_loss: 0.0636 - loss: 0.2754 - learning_rate: 6.3695e-04 - gradient_norm: 1.611/44 [======>.......................] - ETA: 7s - det_loss: 0.2151 - cls_loss: 0.2066 - box_loss: 1.7072e-04 - reg_l2_loss: 0.0636 - loss: 0.2787 - learning_rate: 6.3336e-04 - gradient_norm: 1.612/44 [=======>......................] - ETA: 7s - det_loss: 0.2166 - cls_loss: 0.2079 - box_loss: 1.7297e-04 - reg_l2_loss: 0.0636 - loss: 0.2801 - learning_rate: 6.2978e-04 - gradient_norm: 1.613/44 [=======>......................] - ETA: 6s - det_loss: 0.2155 - cls_loss: 0.2069 - box_loss: 1.7076e-04 - reg_l2_loss: 0.0636 - loss: 0.2790 - learning_rate: 6.2621e-04 - gradient_norm: 1.614/44 [========>.....................] - ETA: 6s - det_loss: 0.2179 - cls_loss: 0.2093 - box_loss: 1.7276e-04 - reg_l2_loss: 0.0636 - loss: 0.2815 - learning_rate: 6.2266e-04 - gradient_norm: 1.615/44 [=========>....................] - ETA: 6s - det_loss: 0.2190 - cls_loss: 0.2106 - box_loss: 1.6818e-04 - reg_l2_loss: 0.0636 - loss: 0.2825 - learning_rate: 6.1911e-04 - gradient_norm: 1.616/44 [=========>....................] - ETA: 6s - det_loss: 0.2176 - cls_loss: 0.2093 - box_loss: 1.6635e-04 - reg_l2_loss: 0.0636 - loss: 0.2812 - learning_rate: 6.1559e-04 - gradient_norm: 1.717/44 [==========>...................] - ETA: 5s - det_loss: 0.2159 - cls_loss: 0.2074 - box_loss: 1.6914e-04 - reg_l2_loss: 0.0636 - loss: 0.2794 - learning_rate: 6.1207e-04 - gradient_norm: 1.718/44 [===========>..................] - ETA: 5s - det_loss: 0.2166 - cls_loss: 0.2083 - box_loss: 1.6648e-04 - reg_l2_loss: 0.0636 - loss: 0.2802 - learning_rate: 6.0857e-04 - gradient_norm: 1.719/44 [===========>..................] - ETA: 5s - det_loss: 0.2166 - cls_loss: 0.2081 - box_loss: 1.7068e-04 - reg_l2_loss: 0.0636 - loss: 0.2802 - learning_rate: 6.0508e-04 - gradient_norm: 1.720/44 [============>.................] - ETA: 5s - det_loss: 0.2135 - cls_loss: 0.2050 - box_loss: 1.6885e-04 - reg_l2_loss: 0.0636 - loss: 0.2770 - learning_rate: 6.0160e-04 - gradient_norm: 1.621/44 [=============>................] - ETA: 5s - det_loss: 0.2144 - cls_loss: 0.2060 - box_loss: 1.6848e-04 - reg_l2_loss: 0.0636 - loss: 0.2780 - learning_rate: 5.9814e-04 - gradient_norm: 1.622/44 [==============>...............] - ETA: 4s - det_loss: 0.2136 - cls_loss: 0.2052 - box_loss: 1.6825e-04 - reg_l2_loss: 0.0636 - loss: 0.2772 - learning_rate: 5.9469e-04 - gradient_norm: 1.723/44 [==============>...............] - ETA: 4s - det_loss: 0.2163 - cls_loss: 0.2077 - box_loss: 1.7237e-04 - reg_l2_loss: 0.0636 - loss: 0.2799 - learning_rate: 5.9125e-04 - gradient_norm: 1.724/44 [===============>..............] - ETA: 4s - det_loss: 0.2140 - cls_loss: 0.2055 - box_loss: 1.7142e-04 - reg_l2_loss: 0.0636 - loss: 0.2776 - learning_rate: 5.8783e-04 - gradient_norm: 1.725/44 [================>.............] - ETA: 4s - det_loss: 0.2167 - cls_loss: 0.2081 - box_loss: 1.7270e-04 - reg_l2_loss: 0.0636 - loss: 0.2803 - learning_rate: 5.8442e-04 - gradient_norm: 1.926/44 [================>.............] - ETA: 3s - det_loss: 0.2172 - cls_loss: 0.2084 - box_loss: 1.7458e-04 - reg_l2_loss: 0.0636 - loss: 0.2807 - learning_rate: 5.8102e-04 - gradient_norm: 2.027/44 [=================>............] - ETA: 3s - det_loss: 0.2149 - cls_loss: 0.2063 - box_loss: 1.7257e-04 - reg_l2_loss: 0.0636 - loss: 0.2784 - learning_rate: 5.7764e-04 - gradient_norm: 1.928/44 [==================>...........] - ETA: 3s - det_loss: 0.2137 - cls_loss: 0.2051 - box_loss: 1.7196e-04 - reg_l2_loss: 0.0636 - loss: 0.2773 - learning_rate: 5.7426e-04 - gradient_norm: 1.929/44 [==================>...........] - ETA: 3s - det_loss: 0.2150 - cls_loss: 0.2064 - box_loss: 1.7211e-04 - reg_l2_loss: 0.0636 - loss: 0.2785 - learning_rate: 5.7091e-04 - gradient_norm: 1.930/44 [===================>..........] - ETA: 3s - det_loss: 0.2139 - cls_loss: 0.2054 - box_loss: 1.7196e-04 - reg_l2_loss: 0.0636 - loss: 0.2775 - learning_rate: 5.6756e-04 - gradient_norm: 1.931/44 [====================>.........] - ETA: 2s - det_loss: 0.2126 - cls_loss: 0.2038 - box_loss: 1.7617e-04 - reg_l2_loss: 0.0636 - loss: 0.2761 - learning_rate: 5.6423e-04 - gradient_norm: 1.932/44 [====================>.........] - ETA: 2s - det_loss: 0.2104 - cls_loss: 0.2017 - box_loss: 1.7448e-04 - reg_l2_loss: 0.0636 - loss: 0.2739 - learning_rate: 5.6091e-04 - gradient_norm: 1.833/44 [=====================>........] - ETA: 2s - det_loss: 0.2112 - cls_loss: 0.2024 - box_loss: 1.7474e-04 - reg_l2_loss: 0.0636 - loss: 0.2747 - learning_rate: 5.5761e-04 - gradient_norm: 1.934/44 [======================>.......] - ETA: 2s - det_loss: 0.2095 - cls_loss: 0.2008 - box_loss: 1.7332e-04 - reg_l2_loss: 0.0636 - loss: 0.2731 - learning_rate: 5.5431e-04 - gradient_norm: 1.935/44 [======================>.......] - ETA: 1s - det_loss: 0.2098 - cls_loss: 0.2011 - box_loss: 1.7413e-04 - reg_l2_loss: 0.0636 - loss: 0.2734 - learning_rate: 5.5103e-04 - gradient_norm: 1.936/44 [=======================>......] - ETA: 1s - det_loss: 0.2109 - cls_loss: 0.2022 - box_loss: 1.7341e-04 - reg_l2_loss: 0.0636 - loss: 0.2744 - learning_rate: 5.4777e-04 - gradient_norm: 1.837/44 [========================>.....] - ETA: 1s - det_loss: 0.2091 - cls_loss: 0.2004 - box_loss: 1.7368e-04 - reg_l2_loss: 0.0636 - loss: 0.2726 - learning_rate: 5.4452e-04 - gradient_norm: 1.838/44 [========================>.....] - ETA: 1s - det_loss: 0.2085 - cls_loss: 0.1996 - box_loss: 1.7760e-04 - reg_l2_loss: 0.0636 - loss: 0.2720 - learning_rate: 5.4128e-04 - gradient_norm: 1.839/44 [=========================>....] - ETA: 1s - det_loss: 0.2060 - cls_loss: 0.1972 - box_loss: 1.7606e-04 - reg_l2_loss: 0.0636 - loss: 0.2695 - learning_rate: 5.3805e-04 - gradient_norm: 1.840/44 [==========================>...] - ETA: 0s - det_loss: 0.2051 - cls_loss: 0.1963 - box_loss: 1.7588e-04 - reg_l2_loss: 0.0636 - loss: 0.2687 - learning_rate: 5.3484e-04 - gradient_norm: 1.841/44 [==========================>...] - ETA: 0s - det_loss: 0.2056 - cls_loss: 0.1968 - box_loss: 1.7642e-04 - reg_l2_loss: 0.0636 - loss: 0.2692 - learning_rate: 5.3164e-04 - gradient_norm: 1.842/44 [===========================>..] - ETA: 0s - det_loss: 0.2059 - cls_loss: 0.1971 - box_loss: 1.7534e-04 - reg_l2_loss: 0.0636 - loss: 0.2694 - learning_rate: 5.2846e-04 - gradient_norm: 1.843/44 [============================>.] - ETA: 0s - det_loss: 0.2063 - cls_loss: 0.1976 - box_loss: 1.7415e-04 - reg_l2_loss: 0.0636 - loss: 0.2699 - learning_rate: 5.2529e-04 - gradient_norm: 1.844/44 [==============================] - ETA: 0s - det_loss: 0.2058 - cls_loss: 0.1971 - box_loss: 1.7471e-04 - reg_l2_loss: 0.0636 - loss: 0.2694 - learning_rate: 5.2213e-04 - gradient_norm: 1.844/44 [==============================] - 11s 256ms/step - det_loss: 0.2054 - cls_loss: 0.1966 - box_loss: 1.7525e-04 - reg_l2_loss: 0.0636 - loss: 0.2689 - learning_rate: 5.1911e-04 - gradient_norm: 1.8244 - val_det_loss: 0.3189 - val_cls_loss: 0.3138 - val_box_loss: 1.0335e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3825
Epoch 22/25
 1/44 [..............................] - ETA: 9s - det_loss: 0.2099 - cls_loss: 0.1999 - box_loss: 2.0038e-04 - reg_l2_loss: 0.0636 - loss: 0.2735 - learning_rate: 3.8060e-04 - gradient_norm: 2.0 2/44 [>.............................] - ETA: 9s - det_loss: 0.1997 - cls_loss: 0.1894 - box_loss: 2.0571e-04 - reg_l2_loss: 0.0636 - loss: 0.2633 - learning_rate: 3.7777e-04 - gradient_norm: 1.6 3/44 [=>............................] - ETA: 8s - det_loss: 0.1748 - cls_loss: 0.1664 - box_loss: 1.6882e-04 - reg_l2_loss: 0.0636 - loss: 0.2384 - learning_rate: 3.7494e-04 - gradient_norm: 1.3 4/44 [=>............................] - ETA: 8s - det_loss: 0.1764 - cls_loss: 0.1680 - box_loss: 1.6791e-04 - reg_l2_loss: 0.0636 - loss: 0.2400 - learning_rate: 3.7213e-04 - gradient_norm: 1.4 5/44 [==>...........................] - ETA: 8s - det_loss: 0.1773 - cls_loss: 0.1694 - box_loss: 1.5760e-04 - reg_l2_loss: 0.0636 - loss: 0.2408 - learning_rate: 3.6934e-04 - gradient_norm: 1.4 6/44 [===>..........................] - ETA: 8s - det_loss: 0.1773 - cls_loss: 0.1696 - box_loss: 1.5294e-04 - reg_l2_loss: 0.0636 - loss: 0.2408 - learning_rate: 3.6656e-04 - gradient_norm: 1.4 7/44 [===>..........................] - ETA: 8s - det_loss: 0.1815 - cls_loss: 0.1732 - box_loss: 1.6690e-04 - reg_l2_loss: 0.0636 - loss: 0.2451 - learning_rate: 3.6379e-04 - gradient_norm: 1.4 8/44 [====>.........................] - ETA: 7s - det_loss: 0.1935 - cls_loss: 0.1848 - box_loss: 1.7479e-04 - reg_l2_loss: 0.0636 - loss: 0.2571 - learning_rate: 3.6104e-04 - gradient_norm: 1.4 9/44 [=====>........................] - ETA: 7s - det_loss: 0.2052 - cls_loss: 0.1970 - box_loss: 1.6496e-04 - reg_l2_loss: 0.0636 - loss: 0.2688 - learning_rate: 3.5830e-04 - gradient_norm: 1.410/44 [=====>........................] - ETA: 7s - det_loss: 0.2063 - cls_loss: 0.1981 - box_loss: 1.6250e-04 - reg_l2_loss: 0.0636 - loss: 0.2698 - learning_rate: 3.5557e-04 - gradient_norm: 1.511/44 [======>.......................] - ETA: 7s - det_loss: 0.2045 - cls_loss: 0.1966 - box_loss: 1.5935e-04 - reg_l2_loss: 0.0636 - loss: 0.2681 - learning_rate: 3.5286e-04 - gradient_norm: 1.412/44 [=======>......................] - ETA: 7s - det_loss: 0.2008 - cls_loss: 0.1930 - box_loss: 1.5470e-04 - reg_l2_loss: 0.0636 - loss: 0.2643 - learning_rate: 3.5016e-04 - gradient_norm: 1.413/44 [=======>......................] - ETA: 6s - det_loss: 0.1986 - cls_loss: 0.1907 - box_loss: 1.5769e-04 - reg_l2_loss: 0.0636 - loss: 0.2622 - learning_rate: 3.4747e-04 - gradient_norm: 1.414/44 [========>.....................] - ETA: 6s - det_loss: 0.1990 - cls_loss: 0.1910 - box_loss: 1.6026e-04 - reg_l2_loss: 0.0636 - loss: 0.2626 - learning_rate: 3.4480e-04 - gradient_norm: 1.415/44 [=========>....................] - ETA: 6s - det_loss: 0.2023 - cls_loss: 0.1938 - box_loss: 1.6943e-04 - reg_l2_loss: 0.0636 - loss: 0.2658 - learning_rate: 3.4214e-04 - gradient_norm: 1.416/44 [=========>....................] - ETA: 6s - det_loss: 0.1968 - cls_loss: 0.1883 - box_loss: 1.7000e-04 - reg_l2_loss: 0.0636 - loss: 0.2604 - learning_rate: 3.3950e-04 - gradient_norm: 1.417/44 [==========>...................] - ETA: 5s - det_loss: 0.1964 - cls_loss: 0.1879 - box_loss: 1.6944e-04 - reg_l2_loss: 0.0636 - loss: 0.2599 - learning_rate: 3.3687e-04 - gradient_norm: 1.418/44 [===========>..................] - ETA: 5s - det_loss: 0.1936 - cls_loss: 0.1851 - box_loss: 1.6859e-04 - reg_l2_loss: 0.0636 - loss: 0.2571 - learning_rate: 3.3425e-04 - gradient_norm: 1.419/44 [===========>..................] - ETA: 5s - det_loss: 0.1941 - cls_loss: 0.1859 - box_loss: 1.6435e-04 - reg_l2_loss: 0.0636 - loss: 0.2577 - learning_rate: 3.3165e-04 - gradient_norm: 1.420/44 [============>.................] - ETA: 5s - det_loss: 0.1913 - cls_loss: 0.1830 - box_loss: 1.6549e-04 - reg_l2_loss: 0.0636 - loss: 0.2549 - learning_rate: 3.2906e-04 - gradient_norm: 1.421/44 [=============>................] - ETA: 5s - det_loss: 0.1907 - cls_loss: 0.1824 - box_loss: 1.6679e-04 - reg_l2_loss: 0.0636 - loss: 0.2543 - learning_rate: 3.2649e-04 - gradient_norm: 1.322/44 [==============>...............] - ETA: 4s - det_loss: 0.1922 - cls_loss: 0.1840 - box_loss: 1.6449e-04 - reg_l2_loss: 0.0636 - loss: 0.2558 - learning_rate: 3.2393e-04 - gradient_norm: 1.423/44 [==============>...............] - ETA: 4s - det_loss: 0.1922 - cls_loss: 0.1840 - box_loss: 1.6432e-04 - reg_l2_loss: 0.0636 - loss: 0.2558 - learning_rate: 3.2138e-04 - gradient_norm: 1.424/44 [===============>..............] - ETA: 4s - det_loss: 0.1927 - cls_loss: 0.1847 - box_loss: 1.6114e-04 - reg_l2_loss: 0.0636 - loss: 0.2563 - learning_rate: 3.1885e-04 - gradient_norm: 1.425/44 [================>.............] - ETA: 4s - det_loss: 0.1929 - cls_loss: 0.1848 - box_loss: 1.6164e-04 - reg_l2_loss: 0.0636 - loss: 0.2564 - learning_rate: 3.1633e-04 - gradient_norm: 1.426/44 [================>.............] - ETA: 3s - det_loss: 0.1918 - cls_loss: 0.1838 - box_loss: 1.6004e-04 - reg_l2_loss: 0.0636 - loss: 0.2554 - learning_rate: 3.1382e-04 - gradient_norm: 1.427/44 [=================>............] - ETA: 3s - det_loss: 0.1917 - cls_loss: 0.1837 - box_loss: 1.6000e-04 - reg_l2_loss: 0.0636 - loss: 0.2553 - learning_rate: 3.1133e-04 - gradient_norm: 1.428/44 [==================>...........] - ETA: 3s - det_loss: 0.1908 - cls_loss: 0.1829 - box_loss: 1.5817e-04 - reg_l2_loss: 0.0636 - loss: 0.2543 - learning_rate: 3.0886e-04 - gradient_norm: 1.429/44 [==================>...........] - ETA: 3s - det_loss: 0.1944 - cls_loss: 0.1856 - box_loss: 1.7533e-04 - reg_l2_loss: 0.0636 - loss: 0.2579 - learning_rate: 3.0639e-04 - gradient_norm: 1.530/44 [===================>..........] - ETA: 3s - det_loss: 0.1922 - cls_loss: 0.1835 - box_loss: 1.7469e-04 - reg_l2_loss: 0.0636 - loss: 0.2558 - learning_rate: 3.0394e-04 - gradient_norm: 1.531/44 [====================>.........] - ETA: 2s - det_loss: 0.1918 - cls_loss: 0.1831 - box_loss: 1.7303e-04 - reg_l2_loss: 0.0636 - loss: 0.2553 - learning_rate: 3.0151e-04 - gradient_norm: 1.532/44 [====================>.........] - ETA: 2s - det_loss: 0.1908 - cls_loss: 0.1823 - box_loss: 1.7096e-04 - reg_l2_loss: 0.0636 - loss: 0.2544 - learning_rate: 2.9909e-04 - gradient_norm: 1.433/44 [=====================>........] - ETA: 2s - det_loss: 0.1901 - cls_loss: 0.1816 - box_loss: 1.7090e-04 - reg_l2_loss: 0.0636 - loss: 0.2537 - learning_rate: 2.9668e-04 - gradient_norm: 1.434/44 [======================>.......] - ETA: 2s - det_loss: 0.1924 - cls_loss: 0.1839 - box_loss: 1.7073e-04 - reg_l2_loss: 0.0636 - loss: 0.2560 - learning_rate: 2.9428e-04 - gradient_norm: 1.535/44 [======================>.......] - ETA: 1s - det_loss: 0.1934 - cls_loss: 0.1848 - box_loss: 1.7188e-04 - reg_l2_loss: 0.0636 - loss: 0.2570 - learning_rate: 2.9190e-04 - gradient_norm: 1.536/44 [=======================>......] - ETA: 1s - det_loss: 0.1927 - cls_loss: 0.1842 - box_loss: 1.7031e-04 - reg_l2_loss: 0.0636 - loss: 0.2562 - learning_rate: 2.8954e-04 - gradient_norm: 1.537/44 [========================>.....] - ETA: 1s - det_loss: 0.1926 - cls_loss: 0.1840 - box_loss: 1.7250e-04 - reg_l2_loss: 0.0636 - loss: 0.2562 - learning_rate: 2.8719e-04 - gradient_norm: 1.538/44 [========================>.....] - ETA: 1s - det_loss: 0.1928 - cls_loss: 0.1841 - box_loss: 1.7294e-04 - reg_l2_loss: 0.0636 - loss: 0.2563 - learning_rate: 2.8485e-04 - gradient_norm: 1.539/44 [=========================>....] - ETA: 1s - det_loss: 0.1931 - cls_loss: 0.1845 - box_loss: 1.7143e-04 - reg_l2_loss: 0.0636 - loss: 0.2567 - learning_rate: 2.8253e-04 - gradient_norm: 1.540/44 [==========================>...] - ETA: 0s - det_loss: 0.1945 - cls_loss: 0.1860 - box_loss: 1.7130e-04 - reg_l2_loss: 0.0636 - loss: 0.2581 - learning_rate: 2.8022e-04 - gradient_norm: 1.541/44 [==========================>...] - ETA: 0s - det_loss: 0.1940 - cls_loss: 0.1856 - box_loss: 1.6970e-04 - reg_l2_loss: 0.0636 - loss: 0.2576 - learning_rate: 2.7792e-04 - gradient_norm: 1.542/44 [===========================>..] - ETA: 0s - det_loss: 0.1945 - cls_loss: 0.1861 - box_loss: 1.6914e-04 - reg_l2_loss: 0.0636 - loss: 0.2581 - learning_rate: 2.7564e-04 - gradient_norm: 1.543/44 [============================>.] - ETA: 0s - det_loss: 0.1960 - cls_loss: 0.1876 - box_loss: 1.6938e-04 - reg_l2_loss: 0.0636 - loss: 0.2596 - learning_rate: 2.7337e-04 - gradient_norm: 1.544/44 [==============================] - ETA: 0s - det_loss: 0.1956 - cls_loss: 0.1871 - box_loss: 1.6959e-04 - reg_l2_loss: 0.0636 - loss: 0.2591 - learning_rate: 2.7112e-04 - gradient_norm: 1.544/44 [==============================] - 11s 255ms/step - det_loss: 0.1951 - cls_loss: 0.1866 - box_loss: 1.6979e-04 - reg_l2_loss: 0.0636 - loss: 0.2587 - learning_rate: 2.6897e-04 - gradient_norm: 1.5125 - val_det_loss: 0.3145 - val_cls_loss: 0.3094 - val_box_loss: 1.0120e-04 - val_reg_l2_loss: 0.0636 - val_loss: 0.3780
Epoch 23/25
 1/44 [..............................] - ETA: 9s - det_loss: 0.1347 - cls_loss: 0.1252 - box_loss: 1.9119e-04 - reg_l2_loss: 0.0636 - loss: 0.1983 - learning_rate: 1.7037e-04 - gradient_norm: 0.8 2/44 [>.............................] - ETA: 9s - det_loss: 0.1819 - cls_loss: 0.1736 - box_loss: 1.6527e-04 - reg_l2_loss: 0.0636 - loss: 0.2454 - learning_rate: 1.6846e-04 - gradient_norm: 1.1 3/44 [=>............................] - ETA: 9s - det_loss: 0.1853 - cls_loss: 0.1778 - box_loss: 1.4851e-04 - reg_l2_loss: 0.0636 - loss: 0.2488 - learning_rate: 1.6656e-04 - gradient_norm: 0.9 4/44 [=>............................] - ETA: 8s - det_loss: 0.1864 - cls_loss: 0.1783 - box_loss: 1.6197e-04 - reg_l2_loss: 0.0636 - loss: 0.2500 - learning_rate: 1.6467e-04 - gradient_norm: 1.0 5/44 [==>...........................] - ETA: 8s - det_loss: 0.1811 - cls_loss: 0.1728 - box_loss: 1.6538e-04 - reg_l2_loss: 0.0636 - loss: 0.2447 - learning_rate: 1.6280e-04 - gradient_norm: 1.0 6/44 [===>..........................] - ETA: 8s - det_loss: 0.2237 - cls_loss: 0.2155 - box_loss: 1.6385e-04 - reg_l2_loss: 0.0636 - loss: 0.2873 - learning_rate: 1.6094e-04 - gradient_norm: 2.0 7/44 [===>..........................] - ETA: 8s - det_loss: 0.2229 - cls_loss: 0.2140 - box_loss: 1.7746e-04 - reg_l2_loss: 0.0636 - loss: 0.2864 - learning_rate: 1.5910e-04 - gradient_norm: 2.0 8/44 [====>.........................] - ETA: 8s - det_loss: 0.2190 - cls_loss: 0.2100 - box_loss: 1.8024e-04 - reg_l2_loss: 0.0636 - loss: 0.2825 - learning_rate: 1.5727e-04 - gradient_norm: 2.0 9/44 [=====>........................] - ETA: 7s - det_loss: 0.2154 - cls_loss: 0.2065 - box_loss: 1.7843e-04 - reg_l2_loss: 0.0636 - loss: 0.2790 - learning_rate: 1.5546e-04 - gradient_norm: 1.910/44 [=====>........................] - ETA: 7s - det_loss: 0.2139 - cls_loss: 0.2053 - box_loss: 1.7253e-04 - reg_l2_loss: 0.0636 - loss: 0.2775 - learning_rate: 1.5366e-04 - gradient_norm: 1.911/44 [======>.......................] - ETA: 7s - det_loss: 0.2078 - cls_loss: 0.1993 - box_loss: 1.6899e-04 - reg_l2_loss: 0.0636 - loss: 0.2713 - learning_rate: 1.5187e-04 - gradient_norm: 1.912/44 [=======>......................] - ETA: 7s - det_loss: 0.2013 - cls_loss: 0.1928 - box_loss: 1.6967e-04 - reg_l2_loss: 0.0636 - loss: 0.2648 - learning_rate: 1.5010e-04 - gradient_norm: 1.813/44 [=======>......................] - ETA: 6s - det_loss: 0.2083 - cls_loss: 0.1998 - box_loss: 1.7011e-04 - reg_l2_loss: 0.0636 - loss: 0.2719 - learning_rate: 1.4834e-04 - gradient_norm: 1.814/44 [========>.....................] - ETA: 6s - det_loss: 0.2074 - cls_loss: 0.1988 - box_loss: 1.7226e-04 - reg_l2_loss: 0.0636 - loss: 0.2709 - learning_rate: 1.4660e-04 - gradient_norm: 1.715/44 [=========>....................] - ETA: 6s - det_loss: 0.2105 - cls_loss: 0.2017 - box_loss: 1.7726e-04 - reg_l2_loss: 0.0636 - loss: 0.2741 - learning_rate: 1.4487e-04 - gradient_norm: 1.816/44 [=========>....................] - ETA: 6s - det_loss: 0.2127 - cls_loss: 0.2039 - box_loss: 1.7419e-04 - reg_l2_loss: 0.0636 - loss: 0.2762 - learning_rate: 1.4316e-04 - gradient_norm: 1.817/44 [==========>...................] - ETA: 5s - det_loss: 0.2170 - cls_loss: 0.2082 - box_loss: 1.7689e-04 - reg_l2_loss: 0.0636 - loss: 0.2806 - learning_rate: 1.4146e-04 - gradient_norm: 1.818/44 [===========>..................] - ETA: 5s - det_loss: 0.2171 - cls_loss: 0.2084 - box_loss: 1.7327e-04 - reg_l2_loss: 0.0636 - loss: 0.2807 - learning_rate: 1.3977e-04 - gradient_norm: 1.819/44 [===========>..................] - ETA: 5s - det_loss: 0.2133 - cls_loss: 0.2047 - box_loss: 1.7280e-04 - reg_l2_loss: 0.0636 - loss: 0.2769 - learning_rate: 1.3810e-04 - gradient_norm: 1.820/44 [============>.................] - ETA: 5s - det_loss: 0.2134 - cls_loss: 0.2050 - box_loss: 1.6800e-04 - reg_l2_loss: 0.0636 - loss: 0.2770 - learning_rate: 1.3645e-04 - gradient_norm: 1.821/44 [=============>................] - ETA: 5s - det_loss: 0.2097 - cls_loss: 0.2014 - box_loss: 1.6617e-04 - reg_l2_loss: 0.0636 - loss: 0.2732 - learning_rate: 1.3480e-04 - gradient_norm: 1.822/44 [==============>...............] - ETA: 4s - det_loss: 0.2090 - cls_loss: 0.2008 - box_loss: 1.6462e-04 - reg_l2_loss: 0.0636 - loss: 0.2726 - learning_rate: 1.3318e-04 - gradient_norm: 1.823/44 [==============>...............] - ETA: 4s - det_loss: 0.2100 - cls_loss: 0.2018 - box_loss: 1.6313e-04 - reg_l2_loss: 0.0636 - loss: 0.2735 - learning_rate: 1.3156e-04 - gradient_norm: 1.724/44 [===============>..............] - ETA: 4s - det_loss: 0.2094 - cls_loss: 0.2011 - box_loss: 1.6505e-04 - reg_l2_loss: 0.0636 - loss: 0.2729 - learning_rate: 1.2996e-04 - gradient_norm: 1.725/44 [================>.............] - ETA: 4s - det_loss: 0.2089 - cls_loss: 0.2007 - box_loss: 1.6294e-04 - reg_l2_loss: 0.0636 - loss: 0.2724 - learning_rate: 1.2838e-04 - gradient_norm: 1.726/44 [================>.............] - ETA: 3s - det_loss: 0.2061 - cls_loss: 0.1979 - box_loss: 1.6361e-04 - reg_l2_loss: 0.0636 - loss: 0.2697 - learning_rate: 1.2681e-04 - gradient_norm: 1.727/44 [=================>............] - ETA: 3s - det_loss: 0.2029 - cls_loss: 0.1947 - box_loss: 1.6301e-04 - reg_l2_loss: 0.0636 - loss: 0.2664 - learning_rate: 1.2525e-04 - gradient_norm: 1.728/44 [==================>...........] - ETA: 3s - det_loss: 0.2030 - cls_loss: 0.1947 - box_loss: 1.6488e-04 - reg_l2_loss: 0.0636 - loss: 0.2665 - learning_rate: 1.2371e-04 - gradient_norm: 1.729/44 [==================>...........] - ETA: 3s - det_loss: 0.2016 - cls_loss: 0.1935 - box_loss: 1.6310e-04 - reg_l2_loss: 0.0636 - loss: 0.2652 - learning_rate: 1.2219e-04 - gradient_norm: 1.630/44 [===================>..........] - ETA: 3s - det_loss: 0.2003 - cls_loss: 0.1922 - box_loss: 1.6169e-04 - reg_l2_loss: 0.0636 - loss: 0.2639 - learning_rate: 1.2068e-04 - gradient_norm: 1.631/44 [====================>.........] - ETA: 2s - det_loss: 0.1993 - cls_loss: 0.1912 - box_loss: 1.6155e-04 - reg_l2_loss: 0.0636 - loss: 0.2628 - learning_rate: 1.1918e-04 - gradient_norm: 1.632/44 [====================>.........] - ETA: 2s - det_loss: 0.1979 - cls_loss: 0.1899 - box_loss: 1.6069e-04 - reg_l2_loss: 0.0636 - loss: 0.2615 - learning_rate: 1.1769e-04 - gradient_norm: 1.633/44 [=====================>........] - ETA: 2s - det_loss: 0.1981 - cls_loss: 0.1902 - box_loss: 1.5869e-04 - reg_l2_loss: 0.0636 - loss: 0.2617 - learning_rate: 1.1623e-04 - gradient_norm: 1.634/44 [======================>.......] - ETA: 2s - det_loss: 0.2005 - cls_loss: 0.1926 - box_loss: 1.5880e-04 - reg_l2_loss: 0.0636 - loss: 0.2641 - learning_rate: 1.1477e-04 - gradient_norm: 1.635/44 [======================>.......] - ETA: 1s - det_loss: 0.2005 - cls_loss: 0.1925 - box_loss: 1.5893e-04 - reg_l2_loss: 0.0636 - loss: 0.2640 - learning_rate: 1.1333e-04 - gradient_norm: 1.636/44 [=======================>......] - ETA: 1s - det_loss: 0.1989 - cls_loss: 0.1909 - box_loss: 1.5958e-04 - reg_l2_loss: 0.0636 - loss: 0.2625 - learning_rate: 1.1191e-04 - gradient_norm: 1.637/44 [========================>.....] - ETA: 1s - det_loss: 0.2021 - cls_loss: 0.1940 - box_loss: 1.6227e-04 - reg_l2_loss: 0.0636 - loss: 0.2656 - learning_rate: 1.1050e-04 - gradient_norm: 1.638/44 [========================>.....] - ETA: 1s - det_loss: 0.2050 - cls_loss: 0.1970 - box_loss: 1.6093e-04 - reg_l2_loss: 0.0636 - loss: 0.2686 - learning_rate: 1.0910e-04 - gradient_norm: 1.639/44 [=========================>....] - ETA: 1s - det_loss: 0.2053 - cls_loss: 0.1972 - box_loss: 1.6091e-04 - reg_l2_loss: 0.0636 - loss: 0.2688 - learning_rate: 1.0772e-04 - gradient_norm: 1.640/44 [==========================>...] - ETA: 0s - det_loss: 0.2051 - cls_loss: 0.1970 - box_loss: 1.6163e-04 - reg_l2_loss: 0.0636 - loss: 0.2686 - learning_rate: 1.0635e-04 - gradient_norm: 1.641/44 [==========================>...] - ETA: 0s - det_loss: 0.2051 - cls_loss: 0.1970 - box_loss: 1.6155e-04 - reg_l2_loss: 0.0636 - loss: 0.2687 - learning_rate: 1.0500e-04 - gradient_norm: 1.642/44 [===========================>..] - ETA: 0s - det_loss: 0.2078 - cls_loss: 0.1997 - box_loss: 1.6138e-04 - reg_l2_loss: 0.0636 - loss: 0.2714 - learning_rate: 1.0366e-04 - gradient_norm: 1.643/44 [============================>.] - ETA: 0s - det_loss: 0.2072 - cls_loss: 0.1991 - box_loss: 1.6070e-04 - reg_l2_loss: 0.0636 - loss: 0.2707 - learning_rate: 1.0234e-04 - gradient_norm: 1.644/44 [==============================] - ETA: 0s - det_loss: 0.2070 - cls_loss: 0.1991 - box_loss: 1.5937e-04 - reg_l2_loss: 0.0636 - loss: 0.2706 - learning_rate: 1.0103e-04 - gradient_norm: 1.644/44 [==============================] - 11s 256ms/step - det_loss: 0.2069 - cls_loss: 0.1990 - box_loss: 1.5809e-04 - reg_l2_loss: 0.0636 - loss: 0.2705 - learning_rate: 9.9777e-05 - gradient_norm: 1.6879 - val_det_loss: 0.3066 - val_cls_loss: 0.3017 - val_box_loss: 9.8670e-05 - val_reg_l2_loss: 0.0636 - val_loss: 0.3702
Epoch 24/25
 1/44 [..............................] - ETA: 9s - det_loss: 0.2238 - cls_loss: 0.2159 - box_loss: 1.5662e-04 - reg_l2_loss: 0.0636 - loss: 0.2873 - learning_rate: 4.2776e-05 - gradient_norm: 1.0 2/44 [>.............................] - ETA: 9s - det_loss: 0.1841 - cls_loss: 0.1773 - box_loss: 1.3515e-04 - reg_l2_loss: 0.0636 - loss: 0.2477 - learning_rate: 4.1816e-05 - gradient_norm: 0.9 3/44 [=>............................] - ETA: 9s - det_loss: 0.1902 - cls_loss: 0.1832 - box_loss: 1.4106e-04 - reg_l2_loss: 0.0636 - loss: 0.2538 - learning_rate: 4.0871e-05 - gradient_norm: 0.9 4/44 [=>............................] - ETA: 9s - det_loss: 0.1865 - cls_loss: 0.1787 - box_loss: 1.5589e-04 - reg_l2_loss: 0.0636 - loss: 0.2501 - learning_rate: 3.9940e-05 - gradient_norm: 0.9 5/44 [==>...........................] - ETA: 8s - det_loss: 0.1863 - cls_loss: 0.1788 - box_loss: 1.5060e-04 - reg_l2_loss: 0.0636 - loss: 0.2498 - learning_rate: 3.9024e-05 - gradient_norm: 1.1 6/44 [===>..........................] - ETA: 8s - det_loss: 0.1981 - cls_loss: 0.1905 - box_loss: 1.5187e-04 - reg_l2_loss: 0.0636 - loss: 0.2617 - learning_rate: 3.8123e-05 - gradient_norm: 1.2 7/44 [===>..........................] - ETA: 8s - det_loss: 0.1898 - cls_loss: 0.1821 - box_loss: 1.5254e-04 - reg_l2_loss: 0.0636 - loss: 0.2533 - learning_rate: 3.7236e-05 - gradient_norm: 1.2 8/44 [====>.........................] - ETA: 7s - det_loss: 0.1873 - cls_loss: 0.1794 - box_loss: 1.5778e-04 - reg_l2_loss: 0.0636 - loss: 0.2509 - learning_rate: 3.6364e-05 - gradient_norm: 1.3 9/44 [=====>........................] - ETA: 7s - det_loss: 0.1933 - cls_loss: 0.1853 - box_loss: 1.5999e-04 - reg_l2_loss: 0.0636 - loss: 0.2569 - learning_rate: 3.5507e-05 - gradient_norm: 1.310/44 [=====>........................] - ETA: 7s - det_loss: 0.1956 - cls_loss: 0.1879 - box_loss: 1.5434e-04 - reg_l2_loss: 0.0636 - loss: 0.2592 - learning_rate: 3.4664e-05 - gradient_norm: 1.311/44 [======>.......................] - ETA: 7s - det_loss: 0.1992 - cls_loss: 0.1915 - box_loss: 1.5473e-04 - reg_l2_loss: 0.0636 - loss: 0.2628 - learning_rate: 3.3836e-05 - gradient_norm: 1.412/44 [=======>......................] - ETA: 7s - det_loss: 0.1964 - cls_loss: 0.1889 - box_loss: 1.4938e-04 - reg_l2_loss: 0.0636 - loss: 0.2600 - learning_rate: 3.3023e-05 - gradient_norm: 1.313/44 [=======>......................] - ETA: 6s - det_loss: 0.1957 - cls_loss: 0.1883 - box_loss: 1.4770e-04 - reg_l2_loss: 0.0636 - loss: 0.2592 - learning_rate: 3.2224e-05 - gradient_norm: 1.414/44 [========>.....................] - ETA: 6s - det_loss: 0.1948 - cls_loss: 0.1874 - box_loss: 1.4707e-04 - reg_l2_loss: 0.0636 - loss: 0.2583 - learning_rate: 3.1440e-05 - gradient_norm: 1.415/44 [=========>....................] - ETA: 6s - det_loss: 0.1951 - cls_loss: 0.1877 - box_loss: 1.4877e-04 - reg_l2_loss: 0.0636 - loss: 0.2587 - learning_rate: 3.0671e-05 - gradient_norm: 1.416/44 [=========>....................] - ETA: 6s - det_loss: 0.1930 - cls_loss: 0.1856 - box_loss: 1.4744e-04 - reg_l2_loss: 0.0636 - loss: 0.2566 - learning_rate: 2.9916e-05 - gradient_norm: 1.417/44 [==========>...................] - ETA: 5s - det_loss: 0.1939 - cls_loss: 0.1862 - box_loss: 1.5350e-04 - reg_l2_loss: 0.0636 - loss: 0.2575 - learning_rate: 2.9176e-05 - gradient_norm: 1.518/44 [===========>..................] - ETA: 5s - det_loss: 0.1951 - cls_loss: 0.1874 - box_loss: 1.5299e-04 - reg_l2_loss: 0.0636 - loss: 0.2586 - learning_rate: 2.8451e-05 - gradient_norm: 1.519/44 [===========>..................] - ETA: 5s - det_loss: 0.2036 - cls_loss: 0.1949 - box_loss: 1.7395e-04 - reg_l2_loss: 0.0636 - loss: 0.2671 - learning_rate: 2.7741e-05 - gradient_norm: 1.820/44 [============>.................] - ETA: 5s - det_loss: 0.2036 - cls_loss: 0.1950 - box_loss: 1.7195e-04 - reg_l2_loss: 0.0636 - loss: 0.2671 - learning_rate: 2.7045e-05 - gradient_norm: 1.721/44 [=============>................] - ETA: 5s - det_loss: 0.2033 - cls_loss: 0.1948 - box_loss: 1.6954e-04 - reg_l2_loss: 0.0636 - loss: 0.2669 - learning_rate: 2.6363e-05 - gradient_norm: 1.722/44 [==============>...............] - ETA: 4s - det_loss: 0.2029 - cls_loss: 0.1943 - box_loss: 1.7253e-04 - reg_l2_loss: 0.0636 - loss: 0.2664 - learning_rate: 2.5697e-05 - gradient_norm: 1.723/44 [==============>...............] - ETA: 4s - det_loss: 0.2038 - cls_loss: 0.1951 - box_loss: 1.7255e-04 - reg_l2_loss: 0.0636 - loss: 0.2673 - learning_rate: 2.5045e-05 - gradient_norm: 1.724/44 [===============>..............] - ETA: 4s - det_loss: 0.2025 - cls_loss: 0.1940 - box_loss: 1.7116e-04 - reg_l2_loss: 0.0636 - loss: 0.2661 - learning_rate: 2.4408e-05 - gradient_norm: 1.725/44 [================>.............] - ETA: 4s - det_loss: 0.2029 - cls_loss: 0.1943 - box_loss: 1.7255e-04 - reg_l2_loss: 0.0636 - loss: 0.2665 - learning_rate: 2.3786e-05 - gradient_norm: 1.726/44 [================>.............] - ETA: 3s - det_loss: 0.2033 - cls_loss: 0.1949 - box_loss: 1.6913e-04 - reg_l2_loss: 0.0636 - loss: 0.2669 - learning_rate: 2.3178e-05 - gradient_norm: 1.727/44 [=================>............] - ETA: 3s - det_loss: 0.2045 - cls_loss: 0.1958 - box_loss: 1.7301e-04 - reg_l2_loss: 0.0636 - loss: 0.2680 - learning_rate: 2.2585e-05 - gradient_norm: 1.728/44 [==================>...........] - ETA: 3s - det_loss: 0.2033 - cls_loss: 0.1947 - box_loss: 1.7193e-04 - reg_l2_loss: 0.0636 - loss: 0.2668 - learning_rate: 2.2007e-05 - gradient_norm: 1.729/44 [==================>...........] - ETA: 3s - det_loss: 0.2014 - cls_loss: 0.1929 - box_loss: 1.7072e-04 - reg_l2_loss: 0.0636 - loss: 0.2650 - learning_rate: 2.1443e-05 - gradient_norm: 1.730/44 [===================>..........] - ETA: 3s - det_loss: 0.1996 - cls_loss: 0.1912 - box_loss: 1.6901e-04 - reg_l2_loss: 0.0636 - loss: 0.2632 - learning_rate: 2.0894e-05 - gradient_norm: 1.631/44 [====================>.........] - ETA: 2s - det_loss: 0.1988 - cls_loss: 0.1903 - box_loss: 1.6984e-04 - reg_l2_loss: 0.0636 - loss: 0.2623 - learning_rate: 2.0360e-05 - gradient_norm: 1.632/44 [====================>.........] - ETA: 2s - det_loss: 0.1999 - cls_loss: 0.1914 - box_loss: 1.7038e-04 - reg_l2_loss: 0.0636 - loss: 0.2635 - learning_rate: 1.9841e-05 - gradient_norm: 1.733/44 [=====================>........] - ETA: 2s - det_loss: 0.2010 - cls_loss: 0.1925 - box_loss: 1.7009e-04 - reg_l2_loss: 0.0636 - loss: 0.2646 - learning_rate: 1.9336e-05 - gradient_norm: 1.634/44 [======================>.......] - ETA: 2s - det_loss: 0.1985 - cls_loss: 0.1900 - box_loss: 1.7050e-04 - reg_l2_loss: 0.0636 - loss: 0.2621 - learning_rate: 1.8846e-05 - gradient_norm: 1.635/44 [======================>.......] - ETA: 1s - det_loss: 0.1991 - cls_loss: 0.1906 - box_loss: 1.7163e-04 - reg_l2_loss: 0.0636 - loss: 0.2627 - learning_rate: 1.8371e-05 - gradient_norm: 1.636/44 [=======================>......] - ETA: 1s - det_loss: 0.1996 - cls_loss: 0.1911 - box_loss: 1.7025e-04 - reg_l2_loss: 0.0636 - loss: 0.2632 - learning_rate: 1.7910e-05 - gradient_norm: 1.637/44 [========================>.....] - ETA: 1s - det_loss: 0.1990 - cls_loss: 0.1906 - box_loss: 1.6811e-04 - reg_l2_loss: 0.0636 - loss: 0.2626 - learning_rate: 1.7464e-05 - gradient_norm: 1.638/44 [========================>.....] - ETA: 1s - det_loss: 0.1998 - cls_loss: 0.1913 - box_loss: 1.6898e-04 - reg_l2_loss: 0.0636 - loss: 0.2633 - learning_rate: 1.7033e-05 - gradient_norm: 1.639/44 [=========================>....] - ETA: 1s - det_loss: 0.1991 - cls_loss: 0.1907 - box_loss: 1.6915e-04 - reg_l2_loss: 0.0636 - loss: 0.2627 - learning_rate: 1.6617e-05 - gradient_norm: 1.640/44 [==========================>...] - ETA: 0s - det_loss: 0.2012 - cls_loss: 0.1928 - box_loss: 1.6787e-04 - reg_l2_loss: 0.0636 - loss: 0.2647 - learning_rate: 1.6216e-05 - gradient_norm: 1.641/44 [==========================>...] - ETA: 0s - det_loss: 0.2040 - cls_loss: 0.1955 - box_loss: 1.6991e-04 - reg_l2_loss: 0.0636 - loss: 0.2675 - learning_rate: 1.5829e-05 - gradient_norm: 1.742/44 [===========================>..] - ETA: 0s - det_loss: 0.2036 - cls_loss: 0.1952 - box_loss: 1.6833e-04 - reg_l2_loss: 0.0636 - loss: 0.2672 - learning_rate: 1.5457e-05 - gradient_norm: 1.743/44 [============================>.] - ETA: 0s - det_loss: 0.2028 - cls_loss: 0.1943 - box_loss: 1.6941e-04 - reg_l2_loss: 0.0636 - loss: 0.2663 - learning_rate: 1.5099e-05 - gradient_norm: 1.744/44 [==============================] - ETA: 0s - det_loss: 0.2036 - cls_loss: 0.1952 - box_loss: 1.6827e-04 - reg_l2_loss: 0.0636 - loss: 0.2671 - learning_rate: 1.4756e-05 - gradient_norm: 1.744/44 [==============================] - 11s 261ms/step - det_loss: 0.2044 - cls_loss: 0.1960 - box_loss: 1.6719e-04 - reg_l2_loss: 0.0636 - loss: 0.2679 - learning_rate: 1.4429e-05 - gradient_norm: 1.7355 - val_det_loss: 0.3038 - val_cls_loss: 0.2989 - val_box_loss: 9.8144e-05 - val_reg_l2_loss: 0.0636 - val_loss: 0.3674
Epoch 25/25
 1/44 [..............................] - ETA: 9s - det_loss: 0.1539 - cls_loss: 0.1443 - box_loss: 1.9070e-04 - reg_l2_loss: 0.0636 - loss: 0.2174 - learning_rate: 0.0000e+00 - gradient_norm: 1.3 2/44 [>.............................] - ETA: 9s - det_loss: 0.1706 - cls_loss: 0.1611 - box_loss: 1.8888e-04 - reg_l2_loss: 0.0636 - loss: 0.2341 - learning_rate: 1.1027e-08 - gradient_norm: 1.2 3/44 [=>............................] - ETA: 8s - det_loss: 0.2022 - cls_loss: 0.1931 - box_loss: 1.8178e-04 - reg_l2_loss: 0.0636 - loss: 0.2657 - learning_rate: 3.6856e-08 - gradient_norm: 1.6 4/44 [=>............................] - ETA: 8s - det_loss: 0.1943 - cls_loss: 0.1850 - box_loss: 1.8527e-04 - reg_l2_loss: 0.0636 - loss: 0.2578 - learning_rate: 7.7412e-08 - gradient_norm: 1.5 5/44 [==>...........................] - ETA: 8s - det_loss: 0.2052 - cls_loss: 0.1961 - box_loss: 1.8270e-04 - reg_l2_loss: 0.0636 - loss: 0.2688 - learning_rate: 1.3274e-07 - gradient_norm: 1.5 6/44 [===>..........................] - ETA: 8s - det_loss: 0.2026 - cls_loss: 0.1939 - box_loss: 1.7417e-04 - reg_l2_loss: 0.0636 - loss: 0.2662 - learning_rate: 2.0280e-07 - gradient_norm: 1.4 7/44 [===>..........................] - ETA: 8s - det_loss: 0.2081 - cls_loss: 0.1995 - box_loss: 1.7250e-04 - reg_l2_loss: 0.0636 - loss: 0.2717 - learning_rate: 2.8763e-07 - gradient_norm: 1.5 8/44 [====>.........................] - ETA: 7s - det_loss: 0.2143 - cls_loss: 0.2055 - box_loss: 1.7611e-04 - reg_l2_loss: 0.0636 - loss: 0.2779 - learning_rate: 3.8721e-07 - gradient_norm: 1.5 9/44 [=====>........................] - ETA: 7s - det_loss: 0.2154 - cls_loss: 0.2068 - box_loss: 1.7166e-04 - reg_l2_loss: 0.0636 - loss: 0.2789 - learning_rate: 5.0154e-07 - gradient_norm: 1.410/44 [=====>........................] - ETA: 7s - det_loss: 0.2090 - cls_loss: 0.2006 - box_loss: 1.6882e-04 - reg_l2_loss: 0.0636 - loss: 0.2726 - learning_rate: 6.3062e-07 - gradient_norm: 1.411/44 [======>.......................] - ETA: 7s - det_loss: 0.2038 - cls_loss: 0.1954 - box_loss: 1.6806e-04 - reg_l2_loss: 0.0636 - loss: 0.2674 - learning_rate: 7.7443e-07 - gradient_norm: 1.412/44 [=======>......................] - ETA: 7s - det_loss: 0.2087 - cls_loss: 0.2003 - box_loss: 1.6861e-04 - reg_l2_loss: 0.0636 - loss: 0.2723 - learning_rate: 9.3299e-07 - gradient_norm: 1.313/44 [=======>......................] - ETA: 6s - det_loss: 0.2141 - cls_loss: 0.2057 - box_loss: 1.6862e-04 - reg_l2_loss: 0.0636 - loss: 0.2777 - learning_rate: 1.1063e-06 - gradient_norm: 1.414/44 [========>.....................] - ETA: 6s - det_loss: 0.2154 - cls_loss: 0.2064 - box_loss: 1.7941e-04 - reg_l2_loss: 0.0636 - loss: 0.2789 - learning_rate: 1.2943e-06 - gradient_norm: 1.415/44 [=========>....................] - ETA: 6s - det_loss: 0.2176 - cls_loss: 0.2083 - box_loss: 1.8558e-04 - reg_l2_loss: 0.0636 - loss: 0.2811 - learning_rate: 1.4971e-06 - gradient_norm: 1.516/44 [=========>....................] - ETA: 6s - det_loss: 0.2130 - cls_loss: 0.2034 - box_loss: 1.9191e-04 - reg_l2_loss: 0.0636 - loss: 0.2765 - learning_rate: 1.7147e-06 - gradient_norm: 1.417/44 [==========>...................] - ETA: 5s - det_loss: 0.2095 - cls_loss: 0.1999 - box_loss: 1.9216e-04 - reg_l2_loss: 0.0636 - loss: 0.2731 - learning_rate: 1.9469e-06 - gradient_norm: 1.418/44 [===========>..................] - ETA: 5s - det_loss: 0.2080 - cls_loss: 0.1986 - box_loss: 1.8872e-04 - reg_l2_loss: 0.0636 - loss: 0.2715 - learning_rate: 2.1939e-06 - gradient_norm: 1.419/44 [===========>..................] - ETA: 5s - det_loss: 0.2078 - cls_loss: 0.1984 - box_loss: 1.8895e-04 - reg_l2_loss: 0.0636 - loss: 0.2714 - learning_rate: 2.4557e-06 - gradient_norm: 1.520/44 [============>.................] - ETA: 5s - det_loss: 0.2072 - cls_loss: 0.1977 - box_loss: 1.9076e-04 - reg_l2_loss: 0.0636 - loss: 0.2708 - learning_rate: 2.7322e-06 - gradient_norm: 1.521/44 [=============>................] - ETA: 5s - det_loss: 0.2038 - cls_loss: 0.1943 - box_loss: 1.9031e-04 - reg_l2_loss: 0.0636 - loss: 0.2674 - learning_rate: 3.0234e-06 - gradient_norm: 1.422/44 [==============>...............] - ETA: 4s - det_loss: 0.2016 - cls_loss: 0.1920 - box_loss: 1.9153e-04 - reg_l2_loss: 0.0636 - loss: 0.2652 - learning_rate: 3.3294e-06 - gradient_norm: 1.423/44 [==============>...............] - ETA: 4s - det_loss: 0.1986 - cls_loss: 0.1891 - box_loss: 1.8983e-04 - reg_l2_loss: 0.0636 - loss: 0.2622 - learning_rate: 3.6501e-06 - gradient_norm: 1.424/44 [===============>..............] - ETA: 4s - det_loss: 0.1966 - cls_loss: 0.1873 - box_loss: 1.8744e-04 - reg_l2_loss: 0.0636 - loss: 0.2602 - learning_rate: 3.9855e-06 - gradient_norm: 1.425/44 [================>.............] - ETA: 4s - det_loss: 0.1939 - cls_loss: 0.1846 - box_loss: 1.8484e-04 - reg_l2_loss: 0.0636 - loss: 0.2574 - learning_rate: 4.3357e-06 - gradient_norm: 1.426/44 [================>.............] - ETA: 3s - det_loss: 0.1959 - cls_loss: 0.1865 - box_loss: 1.8821e-04 - reg_l2_loss: 0.0636 - loss: 0.2594 - learning_rate: 4.7006e-06 - gradient_norm: 1.427/44 [=================>............] - ETA: 3s - det_loss: 0.1944 - cls_loss: 0.1851 - box_loss: 1.8539e-04 - reg_l2_loss: 0.0636 - loss: 0.2580 - learning_rate: 5.0802e-06 - gradient_norm: 1.428/44 [==================>...........] - ETA: 3s - det_loss: 0.1931 - cls_loss: 0.1839 - box_loss: 1.8410e-04 - reg_l2_loss: 0.0636 - loss: 0.2566 - learning_rate: 5.4745e-06 - gradient_norm: 1.429/44 [==================>...........] - ETA: 3s - det_loss: 0.1934 - cls_loss: 0.1843 - box_loss: 1.8311e-04 - reg_l2_loss: 0.0636 - loss: 0.2570 - learning_rate: 5.8836e-06 - gradient_norm: 1.430/44 [===================>..........] - ETA: 3s - det_loss: 0.1939 - cls_loss: 0.1848 - box_loss: 1.8134e-04 - reg_l2_loss: 0.0636 - loss: 0.2575 - learning_rate: 6.3073e-06 - gradient_norm: 1.431/44 [====================>.........] - ETA: 2s - det_loss: 0.1980 - cls_loss: 0.1888 - box_loss: 1.8454e-04 - reg_l2_loss: 0.0636 - loss: 0.2616 - learning_rate: 6.7458e-06 - gradient_norm: 1.532/44 [====================>.........] - ETA: 2s - det_loss: 0.1979 - cls_loss: 0.1887 - box_loss: 1.8361e-04 - reg_l2_loss: 0.0636 - loss: 0.2615 - learning_rate: 7.1990e-06 - gradient_norm: 1.533/44 [=====================>........] - ETA: 2s - det_loss: 0.2010 - cls_loss: 0.1916 - box_loss: 1.8820e-04 - reg_l2_loss: 0.0636 - loss: 0.2646 - learning_rate: 7.6670e-06 - gradient_norm: 1.534/44 [======================>.......] - ETA: 2s - det_loss: 0.2010 - cls_loss: 0.1915 - box_loss: 1.8953e-04 - reg_l2_loss: 0.0636 - loss: 0.2645 - learning_rate: 8.1496e-06 - gradient_norm: 1.535/44 [======================>.......] - ETA: 1s - det_loss: 0.2015 - cls_loss: 0.1920 - box_loss: 1.8991e-04 - reg_l2_loss: 0.0636 - loss: 0.2650 - learning_rate: 8.6469e-06 - gradient_norm: 1.536/44 [=======================>......] - ETA: 1s - det_loss: 0.2019 - cls_loss: 0.1925 - box_loss: 1.8751e-04 - reg_l2_loss: 0.0636 - loss: 0.2654 - learning_rate: 9.1590e-06 - gradient_norm: 1.537/44 [========================>.....] - ETA: 1s - det_loss: 0.2006 - cls_loss: 0.1914 - box_loss: 1.8581e-04 - reg_l2_loss: 0.0636 - loss: 0.2642 - learning_rate: 9.6857e-06 - gradient_norm: 1.538/44 [========================>.....] - ETA: 1s - det_loss: 0.1996 - cls_loss: 0.1904 - box_loss: 1.8418e-04 - reg_l2_loss: 0.0636 - loss: 0.2631 - learning_rate: 1.0227e-05 - gradient_norm: 1.539/44 [=========================>....] - ETA: 1s - det_loss: 0.1979 - cls_loss: 0.1888 - box_loss: 1.8300e-04 - reg_l2_loss: 0.0636 - loss: 0.2615 - learning_rate: 1.0783e-05 - gradient_norm: 1.540/44 [==========================>...] - ETA: 0s - det_loss: 0.1966 - cls_loss: 0.1874 - box_loss: 1.8373e-04 - reg_l2_loss: 0.0636 - loss: 0.2601 - learning_rate: 1.1354e-05 - gradient_norm: 1.541/44 [==========================>...] - ETA: 0s - det_loss: 0.1960 - cls_loss: 0.1869 - box_loss: 1.8202e-04 - reg_l2_loss: 0.0636 - loss: 0.2596 - learning_rate: 1.1940e-05 - gradient_norm: 1.542/44 [===========================>..] - ETA: 0s - det_loss: 0.1961 - cls_loss: 0.1871 - box_loss: 1.8059e-04 - reg_l2_loss: 0.0636 - loss: 0.2596 - learning_rate: 1.2540e-05 - gradient_norm: 1.543/44 [============================>.] - ETA: 0s - det_loss: 0.1957 - cls_loss: 0.1867 - box_loss: 1.7959e-04 - reg_l2_loss: 0.0636 - loss: 0.2592 - learning_rate: 1.3155e-05 - gradient_norm: 1.544/44 [==============================] - ETA: 0s - det_loss: 0.1952 - cls_loss: 0.1863 - box_loss: 1.7784e-04 - reg_l2_loss: 0.0636 - loss: 0.2588 - learning_rate: 1.3784e-05 - gradient_norm: 1.544/44 [==============================] - 12s 282ms/step - det_loss: 0.1948 - cls_loss: 0.1860 - box_loss: 1.7617e-04 - reg_l2_loss: 0.0636 - loss: 0.2584 - learning_rate: 1.4386e-05 - gradient_norm: 1.5463 - val_det_loss: 0.2992 - val_cls_loss: 0.2943 - val_box_loss: 9.8081e-05 - val_reg_l2_loss: 0.0636 - val_loss: 0.3627
=============Validation results==============

2023-03-31 06:13:14.670914: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2/2 [==============================] - 10s 2s/step

{'AP': 0.5436719, 'AP50': 0.5984966, 'AP75': 0.55164546, 'APs': -1.0, 'APm': -1.0, 'APl': 0.5436755, 'ARmax1': 0.80732083, 'ARmax10': 0.8583046, 'ARmax100': 0.8583046, 'ARs': -1.0, 'ARm': -1.0, 'ARl': 0.8583046, 'AP_/clear': 0.9327163, 'AP_/left': 0.2558432, 'AP_/right': 0.5766633, 'AP_/center': 0.40946478}
=============Test results==============

1/1 [==============================] - 6s 6s/step

{'AP': 0.78941333, 'AP50': 0.8174937, 'AP75': 0.8032187, 'APs': -1.0, 'APm': -1.0, 'APl': 0.7894221, 'ARmax1': 0.9428442, 'ARmax10': 0.9634058, 'ARmax100': 0.9634058, 'ARs': -1.0, 'ARm': -1.0, 'ARl': 0.9634058, 'AP_/clear': 0.9400645, 'AP_/left': 0.71751016, 'AP_/right': 0.6666667, 'AP_/center': 0.83341193}
2023-03-31 06:13:25.953013: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2023-03-31 06:13:44.535605: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.
2023-03-31 06:13:49.469265: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.
2023-03-31 06:13:49.469306: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.
2023-03-31 06:13:49.470289: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmph0394z_q
2023-03-31 06:13:49.567898: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }
2023-03-31 06:13:49.567952: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmph0394z_q
2023-03-31 06:13:49.870848: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2023-03-31 06:13:51.448800: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmph0394z_q
2023-03-31 06:13:52.097925: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 2627638 microseconds.
2023-03-31 06:13:53.161988: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2023-03-31 06:13:54.440428: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs

Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs
fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0
2023-03-31 06:14:50.309574: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs

Estimated count of arithmetic ops: 1.760 G  ops, equivalently 0.880 G  MACs


Done with model of batch size 8 and epoch 25
